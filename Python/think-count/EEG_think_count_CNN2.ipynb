{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Conv1D network on time series for classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pickle as pkl\n",
    "import itertools \n",
    "import glob\n",
    "from sklearn import svm \n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "%matplotlib inline \n",
    "# %matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(320, 32)\n(320, 32)\n(12,)\n(12,)\n"
    }
   ],
   "source": [
    "#Import datasets\n",
    "think_df = pd.read_pickle(\"F:\\EEG-data\\\\think-count\\splits\\\\0.1s/raw_think.pkl\")\n",
    "count_df = pd.read_pickle(\"F:\\EEG-data\\\\think-count\\splits\\\\0.1s/raw_count.pkl\")\n",
    "\n",
    "print(think_df.shape)\n",
    "print(count_df.shape)\n",
    "print(think_df.iloc[0,0].shape)\n",
    "print(count_df.iloc[0,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Shape each dataframe into 320,12,32\n",
    "def reshape_df(df):\n",
    "    new_df = np.zeros((320,12,32))\n",
    "    for i in range(32):\n",
    "        channel = df.iloc[:,i].values \n",
    "        channel_df = np.zeros((320,12))\n",
    "        for j in range(len(channel)):\n",
    "            channel_df[j,:] = channel[j]\n",
    "        new_df[:,:,i] = keras.utils.normalize(channel_df)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_think_df = reshape_df(think_df)\n",
    "r_count_df = reshape_df(count_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(640, 12, 32)\n(640,)\n"
    }
   ],
   "source": [
    "X = np.vstack((r_think_df,r_count_df))\n",
    "y = np.hstack((np.zeros(r_think_df.shape[0]),np.ones(r_count_df.shape[0])))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test sets\n",
    "def split_train_test(X,y):\n",
    "    sss = StratifiedShuffleSplit(n_splits=5,test_size=0.2,random_state=0)\n",
    "    for train_index, test_index in sss.split(X,y):\n",
    "                x_train, x_test = X[train_index],X[test_index]\n",
    "                y_train, y_test = y[train_index],y[test_index]\n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = split_train_test(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(512, 12, 32)\n(128, 12, 32)\n"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 12, 384)           12672     \n_________________________________________________________________\ndense_4 (Dense)              (None, 12, 10)            3850      \n_________________________________________________________________\ndense_5 (Dense)              (None, 12, 1)             11        \n=================================================================\nTotal params: 16,533\nTrainable params: 16,533\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "#DNN model\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(12*32, input_shape = (12,32), activation=\"relu\"), \n",
    "    tf.keras.layers.Dense(10, activation=\"relu\"), \n",
    "    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/2\n512/512 [==============================] - 2s 3ms/step - loss: 0.0538 - accuracy: 0.9780\nEpoch 2/2\n512/512 [==============================] - 2s 3ms/step - loss: 0.0350 - accuracy: 0.9884\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x26fe73c9828>"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "dataset = dataset.batch(1)\n",
    "\n",
    "model.fit(dataset,epochs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "4/4 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.9108\n0.9108072519302368\n"
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(x_test,y_test) \n",
    "\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bit4f00f251aa71407b905d36ad95b25cdd",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}