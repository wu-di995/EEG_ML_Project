{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining channel importance\n",
    "PSD features, theta and alpha bands only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pickle as pkl\n",
    "import itertools \n",
    "import glob\n",
    "from sklearn import svm \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# %matplotlib inline \n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset\n",
    "t_auc_df = pd.read_pickle(\"F:\\EEG-data\\\\think-count\\\\featureExtraction\\AUC_only/AUC_df_1.pkl\")\n",
    "t_psd_df = pd.read_pickle(\"F:\\EEG-data\\\\think-count\\\\featureExtraction\\PSD_only/PSD_df_1.pkl\")\n",
    "a_auc_df = pd.read_pickle(\"F:\\EEG-data\\\\think-count\\\\featureExtraction\\AUC_only/AUC_df_2.pkl\")\n",
    "a_psd_df = pd.read_pickle(\"F:\\EEG-data\\\\think-count\\\\featureExtraction\\PSD_only/PSD_df_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def apply_SVM_channel(auc_df,psd_df):\n",
    "    channels_list = []\n",
    "    f1_scores = []\n",
    "\n",
    "    sss = StratifiedShuffleSplit(n_splits=5,test_size=0.2,random_state=0)\n",
    "    # bestF1 = {'F1 Score':0,'dataset':'','params':''}\n",
    "    # test_results = {'F1 Score':[],'dataset':[],'params':[]}\n",
    "    #Create PCA instances\n",
    "    pca99 = PCA(n_components=0.99, svd_solver='full')\n",
    "    #Instantiate SVM gridsearch\n",
    "    C_range = [1,3,10,30,100,300,1000]\n",
    "    param_grid= [\n",
    "                # {'C': C_range, 'kernel': ['linear']},\n",
    "                {'C': C_range, 'gamma': [0.001, 0.0001, 'auto', 'scale'], 'kernel': ['rbf']},\n",
    "                ]\n",
    "    scoring = {'f1_macro'}\n",
    "    clf = svm.SVC()\n",
    "    grid = GridSearchCV(clf,param_grid=param_grid,scoring=scoring,cv=5,refit='f1_macro')\n",
    "\n",
    "    for i in range(32):\n",
    "        #Select columns \n",
    "        y = psd_df.iloc[:,-1].values\n",
    "        y1 = auc_df.iloc[:,-1].values\n",
    "        psd_col_select = lambda y: [x for x in list(psd_df.columns) if \"\".join((\"Ch\",str(y),\"_\")) in str(x)]\n",
    "        X = psd_df[psd_col_select(i+1)].values\n",
    "        X1 = auc_df.iloc[:,i].values.reshape(-1,1)\n",
    "        #Split into training and test sets\n",
    "        for train_index, test_index in sss.split(X,y):\n",
    "            X_train, X_test = X[train_index],X[test_index]\n",
    "            y_train, y_test = y[train_index],y[test_index]\n",
    "            X1_train, X1_test = X1[train_index],X1[test_index]\n",
    "            y1_train, y1_test = y1[train_index],y1[test_index]\n",
    "        #Fit transform on training data\n",
    "        x_99_train = pca99.fit_transform(X_train)\n",
    "        #Fit transform on test data\n",
    "        x_99_test = pca99.transform(X_test)\n",
    "        #Gridsearch\n",
    "        grid99 = grid.fit(x_99_train,y_train)\n",
    "        grid991 = grid.fit(X1_train,y1_train)\n",
    "        #Classifiers \n",
    "        clf99 = svm.SVC(**grid99.best_params_)\n",
    "        clf991 = svm.SVC(**grid991.best_params_)\n",
    "        clf99.fit(x_99_train,y_train)\n",
    "        clf991.fit(X1_train,y1_train)\n",
    "        #y_pred\n",
    "        y_99_pred = clf99.predict(x_99_test)\n",
    "        y_991_pred = clf991.predict(X1_test)\n",
    "        #F1 Score \n",
    "        f1Score = f1_score(y_test,y_99_pred,pos_label='T')\n",
    "        f1Score1 = f1_score(y1_test,y_991_pred,pos_label='T')\n",
    "        f1_scores.append(f1Score)\n",
    "        f1_scores.append(f1Score1)\n",
    "        #Channel list\n",
    "        channels_list.append(\"\".join((\"Ch\",str(i+1))))\n",
    "        channels_list.append(\"\".join((\"aCh\",str(i+1))))\n",
    "    #Order lists \n",
    "    \n",
    "    return channels_list,f1_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_channels,t_f1_scores = apply_SVM_channel(t_auc_df,t_psd_df)\n",
    "a_channels,a_f1_scores = apply_SVM_channel(a_auc_df,a_psd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the channels in descending order of F1 scores \n",
    "add_band = lambda channels_list,y: [\"\".join((x,\"_\",y)) for x in channels_list]\n",
    "t_channels1 = add_band(t_channels,\"t\")\n",
    "a_channels1 = add_band(a_channels,\"a\")\n",
    "\n",
    "channels_list = np.array(t_channels1 + a_channels1)\n",
    "f1_scores = np.array(t_f1_scores + a_f1_scores)\n",
    "\n",
    "sorted_channels = channels_list[f1_scores.argsort()[::-1]] #in descending order, best scores first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "128\n"
    }
   ],
   "source": [
    "print(len(sorted_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['aCh19_t' 'Ch19_t' 'Ch22_t' 'aCh11_t' 'Ch24_a' 'Ch11_t' 'aCh15_t'\n 'aCh24_a' 'aCh18_a' 'Ch27_a']\n"
    }
   ],
   "source": [
    "print(sorted_channels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['aCh19_t', 'Ch19_t', 'Ch22_t', 'aCh11_t', 'Ch24_a', 'Ch11_t',\n       'aCh15_t', 'aCh24_a', 'aCh18_a', 'Ch27_a'], dtype='<U7')"
     },
     "metadata": {},
     "execution_count": 233
    }
   ],
   "source": [
    "sorted_channels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bestCh_df(t_auc_df,a_auc_df,t_psd_df,a_psd_df,sorted_channels,no_channels):\n",
    "    channels = sorted_channels[:no_channels]\n",
    "    df_list = [0]*no_channels\n",
    "    for (i,channel) in enumerate(channels):\n",
    "        if channel[-1] == \"t\":\n",
    "            if channel[0] == \"a\": #auc \n",
    "                channel_no = channel[channel.find(\"Ch\")+len(\"Ch\"):channel.find(\"_\")]\n",
    "                df_list[i] = t_auc_df.iloc[:,int(channel_no)-1]\n",
    "            else: #psd\n",
    "                channel_no = channel[channel.find(\"Ch\")+len(\"Ch\"):channel.find(\"_\")]\n",
    "                psd_col_select = lambda y: [x for x in list(t_psd_df.columns) if \"\".join((\"Ch\",str(y),\"_\")) in str(x)]\n",
    "                df_list[i] = t_psd_df[psd_col_select(channel_no)]\n",
    "        elif channel[-1] == \"a\":\n",
    "            if channel[0] == \"a\": #auc \n",
    "                channel_no = channel[channel.find(\"Ch\")+len(\"Ch\"):channel.find(\"_\")]\n",
    "                df_list[i] = a_auc_df.iloc[:,int(channel_no)-1]\n",
    "            else: #psd\n",
    "                channel_no = channel[channel.find(\"Ch\")+len(\"Ch\"):channel.find(\"_\")]\n",
    "                psd_col_select = lambda y: [x for x in list(a_psd_df.columns) if \"\".join((\"Ch\",str(y),\"_\")) in str(x)]\n",
    "                df_list[i] = a_psd_df[psd_col_select(channel_no)]\n",
    "    df_list.append(t_auc_df.iloc[:,-1])\n",
    "    return pd.concat(df_list,axis=1)\n",
    "            \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestCh_df = create_bestCh_df(t_auc_df,a_auc_df,t_psd_df,a_psd_df,sorted_channels,10)\n",
    "# bestCh_df.to_csv(\"F:\\EEG-data\\\\think-count/check.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(640, 26)"
     },
     "metadata": {},
     "execution_count": 235
    }
   ],
   "source": [
    "bestCh_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_CV_SVM(bestChdf):\n",
    "    sss = StratifiedShuffleSplit(n_splits=5,test_size=0.2,random_state=0)\n",
    "    # bestF1 = {'F1 Score':0,'dataset':'','params':''}\n",
    "    # test_results = {'F1 Score':[],'dataset':[],'params':[]}\n",
    "    #Create PCA instances\n",
    "    pca99 = PCA(n_components=0.999, svd_solver='full')\n",
    "    #Instantiate SVM gridsearch\n",
    "    C_range = [1,3,10,30,100,300,1000]\n",
    "    param_grid= [\n",
    "                # {'C': C_range, 'kernel': ['linear']},\n",
    "                {'C': C_range, 'gamma': [0.001, 0.0001, 'auto', 'scale'], 'kernel': ['rbf']},\n",
    "                ]\n",
    "    scoring = {'f1_macro'}\n",
    "    clf = svm.SVC()\n",
    "    grid = GridSearchCV(clf,param_grid=param_grid,scoring=scoring,cv=5,refit='f1_macro')\n",
    "    y = bestChdf.iloc[:,-1].values\n",
    "    X = bestChdf.iloc[:,:-1].values\n",
    "    #Split into training and test sets\n",
    "    for train_index, test_index in sss.split(X,y):\n",
    "        X_train, X_test = X[train_index],X[test_index]\n",
    "        y_train, y_test = y[train_index],y[test_index]\n",
    "    #Fit transform on training data\n",
    "    x_99_train = pca99.fit_transform(X_train)\n",
    "    #Fit transform on test data\n",
    "    x_99_test = pca99.transform(X_test)\n",
    "    #Gridsearch\n",
    "    grid99 = grid.fit(x_99_train,y_train)\n",
    "    #Classifiers \n",
    "    clf99 = svm.SVC(**grid99.best_params_)\n",
    "    clf99.fit(x_99_train,y_train)\n",
    "    #y_pred\n",
    "    y_99_pred = clf99.predict(x_99_test)\n",
    "    #F1 Score \n",
    "    f1Score = f1_score(y_test,y_99_pred,pos_label='T')\n",
    "    return f1Score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_f1Scores = [0]*len(sorted_channels)\n",
    "for i in range(1,len(sorted_channels)+1):\n",
    "    bestCh_df = create_bestCh_df(t_auc_df,a_auc_df,t_psd_df,a_psd_df,sorted_channels,i)\n",
    "    channels_f1Scores[i-1] = PCA_CV_SVM(bestCh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.linspace(1,128,128),channels_f1Scores)\n",
    "ax.set_xlabel(\"No. of features, starting from most important\")\n",
    "ax.set_ylabel(\"F1 Score\")\n",
    "ax.set_title(\"Think-count, channel importance using PSD estimates\")\n",
    "# ax.set_xticks(np.linspace(1,128,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Highest F1 score: 0.8088235294117647\n"
    }
   ],
   "source": [
    "maxF1 = max(channels_f1Scores)\n",
    "print(\"Highest F1 score:\",maxF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "No. of channels used to obtain highest F1 score: 68\nChannels used: ['aCh19_t' 'Ch19_t' 'Ch22_t' 'aCh11_t' 'Ch24_a' 'Ch11_t' 'aCh15_t'\n 'aCh24_a' 'aCh18_a' 'Ch27_a' 'aCh18_t' 'aCh15_a' 'aCh8_a' 'aCh22_t'\n 'aCh20_t' 'aCh7_a' 'Ch13_t' 'aCh27_a' 'aCh6_t' 'Ch18_a' 'aCh12_a' 'Ch6_t'\n 'Ch8_a' 'aCh11_a' 'aCh20_a' 'aCh13_t' 'aCh23_a' 'aCh30_t' 'Ch11_a'\n 'aCh12_t' 'Ch15_t' 'Ch12_a' 'Ch20_t' 'Ch19_a' 'aCh17_t' 'aCh9_a' 'Ch7_a'\n 'aCh25_a' 'Ch18_t' 'aCh32_t' 'Ch30_t' 'Ch23_a' 'Ch29_a' 'Ch21_a'\n 'aCh19_a' 'Ch30_a' 'Ch9_a' 'aCh30_a' 'aCh14_a' 'Ch25_a' 'Ch22_a'\n 'aCh10_a' 'aCh29_a' 'Ch12_t' 'Ch20_a' 'aCh21_a' 'Ch24_t' 'aCh29_t'\n 'aCh23_t' 'Ch4_a' 'aCh5_a' 'Ch6_a' 'Ch16_a' 'aCh4_a' 'aCh22_a' 'aCh21_t'\n 'Ch21_t' 'Ch5_a']\n"
    }
   ],
   "source": [
    "maxF1_channels = sorted_channels[:np.array(channels_f1Scores).argmax()]\n",
    "print(\"No. of channels used to obtain highest F1 score:\", len(maxF1_channels))\n",
    "print(\"Channels used:\",maxF1_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most frequently used channels \n",
    "maxF1_channelsDict = {}\n",
    "for channel in maxF1_channels:\n",
    "    channel = channel[channel.find(\"Ch\"):channel.find(\"_\")]\n",
    "    if channel not in maxF1_channelsDict.keys():\n",
    "        maxF1_channelsDict[channel] = 1\n",
    "    else:\n",
    "        maxF1_channelsDict[channel]+=1\n",
    "maxF1_channelsDict = {k:v for k,v in sorted(maxF1_channelsDict.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'Ch19': 4, 'Ch22': 4, 'Ch11': 4, 'Ch18': 4, 'Ch20': 4, 'Ch12': 4, 'Ch30': 4, 'Ch21': 4, 'Ch24': 3, 'Ch15': 3, 'Ch6': 3, 'Ch23': 3, 'Ch29': 3, 'Ch27': 2, 'Ch8': 2, 'Ch7': 2, 'Ch13': 2, 'Ch9': 2, 'Ch25': 2, 'Ch4': 2, 'Ch5': 2, 'Ch17': 1, 'Ch32': 1, 'Ch14': 1, 'Ch10': 1, 'Ch16': 1}\n"
    }
   ],
   "source": [
    "print(maxF1_channelsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(maxF1_channelsDict)),maxF1_channelsDict.values())\n",
    "plt.xticks(range(len(maxF1_channelsDict)),list(maxF1_channelsDict.keys()))\n",
    "plt.title(\"Think-count, Most commonly used channels for highest F1 Score\")\n",
    "plt.ylabel(\"No. of occurence\")\n",
    "plt.xlabel(\"Channels\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.6206896551724138\n128\n---------\n2\n0.5655172413793104\n128\n---------\n2\n0.5344827586206896\n127\n---------\n2\n0.546875\n126\n---------\n2\n0.5636363636363637\n125\n---------\n2\n0.5652173913043478\n124\n---------\n2\n0.5547445255474454\n123\n---------\n2\n0.5333333333333333\n122\n---------\n2\n0.6393442622950819\n121\n---------\n3\n0.49541284403669716\n121\n---------\n3\n0.4466019417475728\n120\n---------\n3\n0.5862068965517242\n119\n---------\n3\n0.5573770491803278\n118\n---------\n3\n0.5504587155963303\n117\n---------\n3\n0.4466019417475728\n116\n---------\n3\n0.5891472868217055\n115\n---------\n3\n0.5081967213114754\n114\n---------\n3\n0.4672897196261682\n113\n---------\n3\n0.5046728971962616\n112\n---------\n3\n0.6016260162601625\n111\n---------\n3\n0.49090909090909096\n110\n---------\n3\n0.5357142857142857\n109\n---------\n3\n0.5528455284552846\n108\n---------\n3\n0.6153846153846154\n107\n---------\n3\n0.5208333333333334\n106\n---------\n3\n0.5217391304347826\n105\n---------\n3\n0.6218487394957982\n104\n---------\n3\n0.5789473684210525\n103\n---------\n3\n0.5283018867924528\n102\n---------\n3\n0.47457627118644063\n101\n---------\n3\n0.4778761061946903\n100\n---------\n3\n0.5666666666666667\n99\n---------\n3\n0.5357142857142857\n98\n---------\n3\n0.4807692307692308\n97\n---------\n3\n0.5123966942148761\n96\n---------\n3\n0.5846153846153846\n95\n---------\n3\n0.5365853658536586\n94\n---------\n3\n0.5283018867924528\n93\n---------\n3\n0.4424778761061947\n92\n---------\n3\n0.5309734513274337\n91\n---------\n3\n0.573913043478261\n90\n---------\n3\n0.564102564102564\n89\n---------\n3\n0.59375\n88\n---------\n3\n0.5178571428571429\n87\n---------\n3\n0.5046728971962616\n86\n---------\n3\n0.5306122448979592\n85\n---------\n3\n0.6423357664233577\n84\n---------\n4\n0.4680851063829787\n84\n---------\n4\n0.6212121212121211\n83\n---------\n4\n0.6029411764705882\n82\n---------\n4\n0.6875\n81\n---------\n5\n0.6341463414634146\n81\n---------\n5\n0.624\n80\n---------\n5\n0.6153846153846154\n79\n---------\n5\n0.6356589147286822\n78\n---------\n5\n0.5409836065573771\n77\n---------\n5\n0.5757575757575757\n76\n---------\n5\n0.6666666666666665\n75\n---------\n5\n0.6559999999999999\n74\n---------\n5\n0.6000000000000001\n73\n---------\n5\n0.676923076923077\n72\n---------\n5\n0.5945945945945946\n71\n---------\n5\n0.6363636363636364\n70\n---------\n5\n0.637037037037037\n69\n---------\n5\n0.6771653543307087\n68\n---------\n5\n0.6615384615384616\n67\n---------\n5\n0.6000000000000001\n66\n---------\n5\n0.6861313868613139\n65\n---------\n5\n0.6101694915254238\n64\n---------\n5\n0.6559999999999999\n63\n---------\n5\n0.608\n62\n---------\n5\n0.676923076923077\n61\n---------\n5\n0.6717557251908397\n60\n---------\n5\n0.6259541984732824\n59\n---------\n5\n0.5762711864406779\n58\n---------\n5\n0.6141732283464567\n57\n---------\n5\n0.6611570247933884\n56\n---------\n5\n0.6074074074074073\n55\n---------\n5\n0.6666666666666667\n54\n---------\n5\n0.6766917293233083\n53\n---------\n5\n0.6713286713286712\n52\n---------\n5\n0.6153846153846154\n51\n---------\n5\n0.6666666666666667\n50\n---------\n5\n0.6446280991735538\n49\n---------\n5\n0.6466165413533834\n48\n---------\n5\n0.6031746031746031\n47\n---------\n5\n0.5765765765765766\n46\n---------\n5\n0.6721311475409836\n45\n---------\n5\n0.6616541353383458\n44\n---------\n5\n0.5849056603773585\n43\n---------\n5\n0.6515151515151515\n42\n---------\n5\n0.5950413223140496\n41\n---------\n5\n0.6717557251908397\n40\n---------\n5\n0.6564885496183207\n39\n---------\n5\n0.6466165413533834\n38\n---------\n5\n0.6201550387596899\n37\n---------\n5\n0.6451612903225806\n36\n---------\n5\n0.65\n35\n---------\n5\n0.6818181818181819\n34\n---------\n5\n0.5736434108527132\n33\n---------\n5\n0.6666666666666667\n32\n---------\n5\n0.5954198473282443\n31\n---------\n5\n0.6564885496183207\n30\n---------\n5\n0.5499999999999999\n29\n---------\n5\n0.6050420168067226\n28\n---------\n5\n0.6666666666666667\n27\n---------\n5\n0.5950413223140496\n26\n---------\n5\n0.564516129032258\n25\n---------\n5\n0.5606060606060606\n24\n---------\n5\n0.5528455284552846\n23\n---------\n5\n0.6818181818181819\n22\n---------\n5\n0.591304347826087\n21\n---------\n5\n0.6929133858267716\n20\n---------\n6\n0.6363636363636364\n20\n---------\n6\n0.6115702479338843\n19\n---------\n6\n0.6106870229007634\n18\n---------\n6\n0.624\n17\n---------\n6\n0.5765765765765766\n16\n---------\n6\n0.6507936507936509\n15\n---------\n6\n0.64\n14\n---------\n6\n0.6363636363636364\n13\n---------\n6\n0.6559999999999999\n12\n---------\n6\n0.5970149253731343\n11\n---------\n6\n0.5853658536585366\n10\n---------\n6\n0.6315789473684211\n9\n---------\n6\n0.6201550387596899\n8\n---------\n6\n0.6470588235294118\n7\n---------\n6\n0.656934306569343\n6\n---------\n6\n"
    }
   ],
   "source": [
    "#Discard channel if performs is worse after adding it, start from most important channel\n",
    "Dchannels_f1Scores = [0]\n",
    "Dsorted_channels = sorted_channels[:]\n",
    "no_channels = 1\n",
    "for i in range(len(sorted_channels)):\n",
    "    drop_channels = []\n",
    "    bestCh_df = create_bestCh_df(t_auc_df,a_auc_df,t_psd_df,a_psd_df,Dsorted_channels,no_channels)\n",
    "    current_f1Score = PCA_CV_SVM(bestCh_df)\n",
    "    print(current_f1Score)\n",
    "    print(len(Dsorted_channels))\n",
    "    print(\"---------\")\n",
    "    if current_f1Score>Dchannels_f1Scores[-1]:\n",
    "        Dchannels_f1Scores.append(current_f1Score)\n",
    "        no_channels +=1\n",
    "        print(no_channels)\n",
    "    else:\n",
    "        Dsorted_channels = np.delete(Dsorted_channels,np.where(Dsorted_channels==sorted_channels[i]))\n",
    "        print(no_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['aCh19_t' 'aCh18_a' 'Ch9_a' 'Ch22_a' 'Ch32_t']\n['aCh19_t' 'Ch19_t' 'Ch22_t' 'aCh11_t' 'Ch24_a' 'Ch11_t' 'aCh15_t'\n 'aCh24_a' 'aCh18_a' 'Ch27_a' 'aCh18_t' 'aCh15_a' 'aCh8_a' 'aCh22_t'\n 'aCh20_t' 'aCh7_a' 'Ch13_t' 'aCh27_a' 'aCh6_t' 'Ch18_a' 'aCh12_a' 'Ch6_t'\n 'Ch8_a' 'aCh11_a' 'aCh20_a' 'aCh13_t' 'aCh23_a' 'aCh30_t' 'Ch11_a'\n 'aCh12_t' 'Ch15_t' 'Ch12_a' 'Ch20_t' 'Ch19_a' 'aCh17_t' 'aCh9_a' 'Ch7_a'\n 'aCh25_a' 'Ch18_t' 'aCh32_t' 'Ch30_t' 'Ch23_a' 'Ch29_a' 'Ch21_a'\n 'aCh19_a' 'Ch30_a' 'Ch9_a' 'aCh30_a' 'aCh14_a' 'Ch25_a' 'Ch22_a'\n 'aCh10_a' 'aCh29_a' 'Ch12_t' 'Ch20_a' 'aCh21_a' 'Ch24_t' 'aCh29_t'\n 'aCh23_t' 'Ch4_a' 'aCh5_a' 'Ch6_a' 'Ch16_a' 'aCh4_a' 'aCh22_a' 'aCh21_t'\n 'Ch21_t' 'Ch5_a' 'aCh6_a' 'Ch10_a' 'aCh10_t' 'Ch23_t' 'aCh17_a' 'Ch28_t'\n 'Ch13_a' 'aCh27_t' 'aCh3_t' 'Ch14_a' 'aCh24_t' 'aCh9_t' 'Ch29_t' 'Ch14_t'\n 'Ch1_t' 'aCh13_a' 'Ch15_a' 'Ch26_t' 'Ch9_t' 'aCh31_t' 'Ch28_a' 'Ch3_t'\n 'aCh16_a' 'Ch2_a' 'Ch1_a' 'aCh26_t' 'aCh28_a' 'Ch17_a' 'Ch25_t' 'Ch31_t'\n 'aCh1_t' 'aCh5_t' 'aCh25_t' 'Ch27_t' 'Ch26_a' 'Ch10_t' 'aCh3_a' 'aCh16_t'\n 'aCh2_a' 'Ch5_t' 'Ch16_t' 'Ch17_t' 'aCh1_a' 'Ch31_a' 'Ch32_t' 'Ch4_t'\n 'aCh8_t' 'aCh32_a' 'Ch8_t' 'aCh31_a' 'aCh28_t' 'aCh7_t' 'aCh14_t' 'Ch3_a'\n 'aCh4_t' 'Ch32_a' 'Ch7_t' 'aCh2_t' 'aCh26_a' 'Ch2_t']\n"
    }
   ],
   "source": [
    "print(Dsorted_channels)\n",
    "print(sorted_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(Dchannels_f1Scores)\n",
    "ax.set_xlabel(\"No. of features, starting from most important,discard method\")\n",
    "ax.set_ylabel(\"F1 Score\")\n",
    "ax.set_title(\"Think-count, channel importance using PSD estimates\")\n",
    "# ax.set_xticks(np.linspace(1,128,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "128\n"
    }
   ],
   "source": [
    "a = sorted_channels[:]\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "125\n"
    }
   ],
   "source": [
    "b = np.delete(a,(1,3,5))\n",
    "print(len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bit4f00f251aa71407b905d36ad95b25cdd",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}