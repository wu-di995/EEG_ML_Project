{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Music Feature Extraction\n",
    "\n",
    "Goal: Classify types of music by EEG features \n",
    "\n",
    "3 types of music: White Noise, Classical, Hip-Hop \n",
    "Lengths of music (raw): \n",
    "    White Noise: 5934 recorded samples \n",
    "    Classical:   6128 recorded samples \n",
    "    Hip-Hop:     7674 recorded samples \n",
    "Data collection: 128 samples/s, 32 Channels \n",
    "\n",
    "No.of 0.1s samples in filtered data: \n",
    "    White Noise: 494 \n",
    "    Classical:   510\n",
    "    Hip-Hop:     639 \n",
    "    \n",
    "    \n",
    "Feature Extraction steps:</br>\n",
    "1. Get welch's PSD estimate for each channel and plot them \n",
    "2. Create features from PSD estimates:\n",
    "    - PSD estimates for each channel\n",
    "    - Area under PSD for each channel\n",
    "    - Polynomial features\n",
    "3. Create and save datasets \n",
    "    - Combinations of datasets by frequency bands \n",
    "    \n",
    "\n",
    "Work Done: 1,2(not Polynomial),3\n",
    "\n",
    "Problems: Creating Polynomial features took up too much memory to run\n",
    "\n",
    "Future work: Using the multi-taper method, Creating other features, wavelet transform, ratio of bands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import itertools \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# %matplotlib inline \n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 32)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "#Load preprocessed data\n",
    "cwd = os.getcwd() #current directory\n",
    "C_filename = cwd+\"/pkl/preprocessing/C_bands_0.1s_list.pkl\"\n",
    "H_filename = cwd+\"/pkl/preprocessing/H_bands_0.1s_list.pkl\"\n",
    "W_filename = cwd+\"/pkl/preprocessing/W_bands_0.1s_list.pkl\"\n",
    "\n",
    "with open(C_filename,\"rb\") as f:\n",
    "    C_bands_split_list=pkl.load(f)\n",
    "    \n",
    "with open(H_filename,\"rb\") as f:\n",
    "    H_bands_split_list=pkl.load(f)\n",
    "    \n",
    "with open(W_filename,\"rb\") as f:\n",
    "    W_bands_split_list=pkl.load(f)\n",
    "\n",
    "#Checking loaded data\n",
    "if  (all(isinstance(x.shape,tuple) for x in C_bands_split_list) and \n",
    "    all(isinstance(x.shape,tuple) for x in H_bands_split_list) and \n",
    "    all(isinstance(x.shape,tuple) for x in W_bands_split_list)):\n",
    "    \n",
    "    print(C_bands_split_list[0].shape)\n",
    "    print(C_bands_split_list[0].iloc[0,0].shape)\n",
    "    print(H_bands_split_list[0].iloc[0,0].shape)\n",
    "    print(W_bands_split_list[0].iloc[0,0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 32)\n",
      "(639, 32)\n",
      "(494, 32)\n"
     ]
    }
   ],
   "source": [
    "#Apply Welch's method for each item in the dataframes\n",
    "\n",
    "def welch_bands_split_list(bands_list,fs,win,check=False):\n",
    "    #fs -sampling freq, win - number of recorded samples in window\n",
    "    #Using this method, freq resolution = 1/t = fs/N (N=no.of points in windows)\n",
    "    PSD_df_list = [0]*len(bands_list)\n",
    "    for df_no in range(len(bands_list)):\n",
    "        #Every item in the dataframe is mapped to the PSD estimates\n",
    "        PSD_df_list[df_no] = bands_list[df_no].applymap(lambda x: signal.welch(x,fs,nperseg=win)[1])\n",
    "    #Frequency axis for plotting, samee for all\n",
    "    freqs,_ = signal.welch(bands_list[0].iloc[0,0],fs,nperseg=win)\n",
    "    \n",
    "    if check:\n",
    "        if all(isinstance(x.shape,tuple) for x in PSD_df_list):\n",
    "            print(PSD_df_list[0].shape)\n",
    "#         if len(PSD_df_list[0].iloc[0,0]) == len(PSD_df_list[1].iloc[0,0]) == len(PSD_df_list[2].iloc[0,0]) == len(PSD_df_list[3].iloc[0,0]):\n",
    "#             len(PSD_df_list[0].iloc[0,0]\n",
    "    \n",
    "    return freqs, PSD_df_list\n",
    "\n",
    "fs = 128 \n",
    "win = 6 #Half of sample length (12)\n",
    "\n",
    "#Get PSD estimates, freqs is the same for all\n",
    "freqs, C_PSD_df_list = welch_bands_split_list(C_bands_split_list,fs,win,check=True)\n",
    "_, H_PSD_df_list = welch_bands_split_list(H_bands_split_list,fs,win,check=True)\n",
    "_, W_PSD_df_list = welch_bands_split_list(W_bands_split_list,fs,win,check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create features from PSD \n",
    "\n",
    "def get_AUC_PSD_df_list(PSD_df_list):\n",
    "    AUC_PSD_df_list = [0]*len(PSD_df_list)\n",
    "    for df_no in range(len(PSD_df_list)):\n",
    "        AUC_PSD_df_list[df_no] = PSD_df_list[df_no].applymap(lambda x: np.trapz(x))\n",
    "    return AUC_PSD_df_list\n",
    "\n",
    "C_AUC_PSD_df_list = get_AUC_PSD_df_list(C_PSD_df_list)\n",
    "H_AUC_PSD_df_list = get_AUC_PSD_df_list(H_PSD_df_list)\n",
    "W_AUC_PSD_df_list = get_AUC_PSD_df_list(W_PSD_df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 128)\n",
      "(639, 128)\n",
      "(494, 128)\n"
     ]
    }
   ],
   "source": [
    "#Expand all lists in cells to their own variables\n",
    "\n",
    "def expand_PSD_df_list(PSD_df_list):\n",
    "    e_PSD_df_list = [0]*len(PSD_df_list)\n",
    "    for df_no in range(len(PSD_df_list)):\n",
    "        #e_PSD_df_cols_list will be used to create new dataframe\n",
    "        no_PSD = len(PSD_df_list[0].iloc[0,0])\n",
    "        e_PSD_df_cols_list = [0]*32\n",
    "        \n",
    "        for channel in range(len(PSD_df_list[df_no].columns)):\n",
    "            #Expand each column into its own dataframe\n",
    "            new_col = PSD_df_list[df_no][channel].apply(pd.Series)\n",
    "            #Rename every variable in the new column\n",
    "            new_col = new_col.rename(columns = lambda x: \"Ch\"+str(channel+1)+'_'+str(np.linspace(0,64,no_PSD)[x]))\n",
    "            #Add new_col to cols_list\n",
    "            e_PSD_df_cols_list[channel] = new_col\n",
    "        \n",
    "        #Create new dataframe\n",
    "        e_PSD_df = pd.concat(e_PSD_df_cols_list, axis=1)\n",
    "        \n",
    "        #Add to list\n",
    "        e_PSD_df_list[df_no] = e_PSD_df\n",
    "    return e_PSD_df_list \n",
    "\n",
    "C_e_PSD_df_list = expand_PSD_df_list(C_PSD_df_list)\n",
    "H_e_PSD_df_list = expand_PSD_df_list(H_PSD_df_list)\n",
    "W_e_PSD_df_list = expand_PSD_df_list(W_PSD_df_list)\n",
    "\n",
    "print(C_e_PSD_df_list[0].shape)\n",
    "print(H_e_PSD_df_list[0].shape)\n",
    "print(W_e_PSD_df_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,), (1,), (2,), (3,), (4,), (0, 1), (0, 2), (0, 3), (0, 4), (1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4), (0, 1, 2), (0, 1, 3), (0, 1, 4), (0, 2, 3), (0, 2, 4), (0, 3, 4), (1, 2, 3), (1, 2, 4), (1, 3, 4), (2, 3, 4), (0, 1, 2, 3), (0, 1, 2, 4), (0, 1, 3, 4), (0, 2, 3, 4), (1, 2, 3, 4), (0, 1, 2, 3, 4)]\n",
      "<class 'tuple'>\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "#Create datasets with all possible combinations of frequency bands\n",
    "\n",
    "indices = [0,1,2,3,4] #indices representing delta, theta, alpha, beta, gamma bands in order\n",
    "\n",
    "def all_combinations(any_list):\n",
    "    return itertools.chain.from_iterable(\n",
    "        itertools.combinations(any_list, i + 1)\n",
    "        for i in range(len(any_list)))\n",
    "\n",
    "combos = list(all_combinations(indices)) #2^(len(indices))-1 combinations\n",
    "\n",
    "print(combos)\n",
    "print(type(combos[0]))\n",
    "print(len(combos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "(510, 800)\n"
     ]
    }
   ],
   "source": [
    "#Concatenate to form all possible dataframes (PSD and AUC features)\n",
    "\n",
    "#Only PSD features\n",
    "#Only AUC features \n",
    "#Both PSD and AUC features \n",
    "\n",
    "def get_1F_combos_df_list(e_PSD_df_list,combos): \n",
    "    #single feature\n",
    "    combos_df_list = [0]*len(combos)\n",
    "    for i in range(len(combos)):\n",
    "        concat_list = [e_PSD_df_list[x] for x in combos[i]]\n",
    "        combos_df_list[i] = pd.concat(concat_list,axis=1)\n",
    "    return combos_df_list\n",
    "\n",
    "def get_2F_combos_df_list(PSD_df_list,AUC_df_list,combos):\n",
    "    #Two features\n",
    "    combos_df_list = [0]*len(combos)\n",
    "    for i in range(len(combos)):\n",
    "        psd_list = [PSD_df_list[x] for x in combos[i]]\n",
    "        auc_list = [AUC_df_list[x] for x in combos[i]]\n",
    "        concat_list = psd_list + auc_list \n",
    "        combos_df_list[i] = pd.concat(concat_list,axis=1)\n",
    "    return combos_df_list\n",
    "\n",
    "#List of dataframes with only PSD features\n",
    "C_PSD_combos_df_list = get_1F_combos_df_list(C_e_PSD_df_list,combos)\n",
    "H_PSD_combos_df_list = get_1F_combos_df_list(H_e_PSD_df_list,combos)\n",
    "W_PSD_combos_df_list = get_1F_combos_df_list(W_e_PSD_df_list,combos)\n",
    "\n",
    "#List of dataframes with only AUC features\n",
    "C_AUC_combos_df_list = get_1F_combos_df_list(C_AUC_PSD_df_list,combos)\n",
    "H_AUC_combos_df_list = get_1F_combos_df_list(H_AUC_PSD_df_list,combos)\n",
    "W_AUC_combos_df_list = get_1F_combos_df_list(W_AUC_PSD_df_list,combos)\n",
    "\n",
    "#List of dataframes with both features\n",
    "C_2F_combos_df_list = get_2F_combos_df_list(C_e_PSD_df_list,C_AUC_PSD_df_list,combos)\n",
    "H_2F_combos_df_list = get_2F_combos_df_list(H_e_PSD_df_list,H_AUC_PSD_df_list,combos)\n",
    "W_2F_combos_df_list = get_2F_combos_df_list(W_e_PSD_df_list,W_AUC_PSD_df_list,combos)\n",
    "\n",
    "print(len(C_2F_combos_df_list))\n",
    "print(C_2F_combos_df_list[30].shape)\n",
    "\n",
    "# combos_df_list = [0]*len(combos)\n",
    "# concat_list = [C_e_PSD_df_list[x] for x in combos[15]]\n",
    "# combos_df_list = pd.concat(concat_list,axis=1)\n",
    "\n",
    "# H_e_PSD_df_list\n",
    "# W_e_PSD_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append music type columns to all dataframes \n",
    "\n",
    "def add_music_col(df_list,music_type):\n",
    "    new_list = [0]*len(df_list)\n",
    "    for i in range(len(df_list)):\n",
    "        new_df = df_list[i][:]\n",
    "        new_df['Music'] = pd.Series(music_type,index=df_list[i].index) \n",
    "        new_list[i] = new_df\n",
    "    return new_list\n",
    "\n",
    "#Lists\n",
    "#List of dataframes with only PSD features\n",
    "C_PSD_combosM_df_list = add_music_col(C_PSD_combos_df_list,'C')\n",
    "H_PSD_combosM_df_list = add_music_col(H_PSD_combos_df_list,'H')\n",
    "W_PSD_combosM_df_list = add_music_col(W_PSD_combos_df_list,'W')\n",
    "\n",
    "# #List of dataframes with only AUC features\n",
    "C_AUC_combosM_df_list = add_music_col(C_AUC_combos_df_list,'C')\n",
    "H_AUC_combosM_df_list = add_music_col(H_AUC_combos_df_list,'H')\n",
    "W_AUC_combosM_df_list = add_music_col(W_AUC_combos_df_list,'W')\n",
    "\n",
    "# #List of dataframes with both features\n",
    "C_2F_combosM_df_list = add_music_col(C_2F_combos_df_list,'C')\n",
    "H_2F_combosM_df_list = add_music_col(H_2F_combos_df_list,'H')\n",
    "W_2F_combosM_df_list = add_music_col(W_2F_combos_df_list,'W')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine different music types to form full datasets\n",
    "\n",
    "#Create list of strings representing combinations of frequency bands to append to saved files\n",
    "def get_combo_strings(combos):\n",
    "    combo_strings = []\n",
    "    for combo in combos:\n",
    "        strings = [str(x) for x in combo]\n",
    "        string = ''\n",
    "        for i in range(len(strings)):\n",
    "            string += strings[i]\n",
    "        combo_strings.append(string)\n",
    "    return combo_strings\n",
    "combo_strings = get_combo_strings(combos)\n",
    "\n",
    "def concatSave_df_list(C_df_list,H_df_list,W_df_list,combo_strings,filename,savedir):\n",
    "    if len(C_df_list) == len(H_df_list) == len(W_df_list):\n",
    "        for i in range(len(C_df_list)):\n",
    "            new_df = pd.concat([C_df_list[i],H_df_list[i],W_df_list[i]],axis=0)\n",
    "            savepath = savedir+filename+'_'+ combo_strings[i]+'.pkl'\n",
    "            #Save to external HDD as pkl files \n",
    "            new_df.to_pickle(savepath)\n",
    "    else:\n",
    "        print(\"Lists are of unequal lengths.\")\n",
    "\n",
    "\n",
    "PSDsavedir = 'F:/EEG-data/pkl/featureExtraction/PSD_only/'\n",
    "AUCsavedir = 'F:/EEG-data/pkl/featureExtraction/AUC_only/'\n",
    "AUC_PSDsavedir = 'F:/EEG-data/pkl/featureExtraction/AUC_PSD/'\n",
    "\n",
    "PSD_filename = 'PSD_df'\n",
    "AUC_filename = 'AUC_df'\n",
    "AUC_PSDfilename = 'AUC_PSD_df'\n",
    "\n",
    "#\"combosM\" means \"Music\" column has been added\n",
    "#List of dataframes with only PSD features\n",
    "PSD_combosM_df_list = concatSave_df_list(C_PSD_combosM_df_list,H_PSD_combosM_df_list,W_PSD_combosM_df_list, combo_strings,PSD_filename,PSDsavedir)\n",
    "\n",
    "\n",
    "#List of dataframes with only AUC features\n",
    "AUC_combosM_df_list = concatSave_df_list(C_AUC_combosM_df_list,H_AUC_combosM_df_list,W_AUC_combosM_df_list , combo_strings,AUC_filename,AUCsavedir)\n",
    "\n",
    "#List of dataframes with both features\n",
    "AUC_PSD_combosM_df_list = concatSave_df_list(C_2F_combosM_df_list,H_2F_combosM_df_list,W_2F_combosM_df_list , combo_strings,AUC_PSDfilename,AUC_PSDsavedir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Don't do polynomial features for now - too much memory ################\n",
    "\n",
    "# #Generate polynomial features for each dataset \n",
    "# #Storing these as generators to save space, each iterable in the generator is a np array \n",
    "\n",
    "# from sklearn.preprocessing import PolynomialFeatures \n",
    "# poly = PolynomialFeatures(2)\n",
    "\n",
    "# #Generators with only PSD features, polynomial\n",
    "# C_poly_PSD_combos_df_gen = (poly.fit_transform(x) for x in C_PSD_combos_df_list)\n",
    "# H_poly_PSD_combos_df_gen = (poly.fit_transform(x) for x in H_PSD_combos_df_list)\n",
    "# W_poly_PSD_combos_df_gen = (poly.fit_transform(x) for x in W_PSD_combos_df_list)\n",
    "\n",
    "# #Generators with only AUC features, polynomial\n",
    "# C_poly_AUC_combos_df_gen = (poly.fit_transform(x) for x in C_AUC_combos_df_list)\n",
    "# H_poly_AUC_combos_df_gen = (poly.fit_transform(x) for x in H_AUC_combos_df_list)\n",
    "# W_poly_AUC_combos_df_gen = (poly.fit_transform(x) for x in W_AUC_combos_df_list)\n",
    "\n",
    "# #Generators with both features, polynomial\n",
    "# C_poly_2F_combos_df_gen = (poly.fit_transform(x) for x in C_2F_combos_df_list)\n",
    "# H_poly_2F_combos_df_gen = (poly.fit_transform(x) for x in H_2F_combos_df_list)\n",
    "# W_poly_2F_combos_df_gen = (poly.fit_transform(x) for x in W_2F_combos_df_list)\n",
    "\n",
    "# savedir = 'F:/EEG-data/numpy/featureExtraction/'\n",
    "# def get_poly_combos_df(combos_df_list,poly,music_type,filename,savedir):\n",
    "#     for i in range(len(combos_df_list)):\n",
    "#         savepath = savedir+filename+\"_\"+str(i)\n",
    "#         df = poly.fit_transform(combos_df_list[i])\n",
    "#         # music_array = np.array([music_type]*df.shape[0])\n",
    "#         # music_array = music_array.reshape(len(music_array),1)\n",
    "#         # df_M = np.hstack((df,music_array))\n",
    "#         np.savez(savepath,df_M)\n",
    "\n",
    "# get_df_coget_poly_combos_dfs_df_list,poly,'C','C_poly_2F_combos',savedir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Don't do polynomial features for now - too much memory ################\n",
    "\n",
    "# #Append music type columns to all dataframes in generators\n",
    "\n",
    "# #Create list of strings representing combinations of frequency bands to append to saved files\n",
    "# def get_combo_strings(combos):\n",
    "#     combo_strings = []\n",
    "#     for combo in combos:\n",
    "#         strings = [str(x) for x in combo]\n",
    "#         string = ''\n",
    "#         for i in range(len(strings)):\n",
    "#             string += strings[i]\n",
    "#         combo_strings.append(string)\n",
    "#     return combo_strings\n",
    "# combo_strings = get_combo_strings(combos)\n",
    "\n",
    "# #Adds music type column to each dataframe generated\n",
    "# def add_music_col_gen(generator,music_type,combo_strings,filename,savedir):\n",
    "#     i=0\n",
    "#     while i<len(combo_strings):\n",
    "#         df = next(generator)\n",
    "#         music_array = np.array([music_type]*df.shape[0])\n",
    "#         music_array = music_array.reshape(len(music_array),1)\n",
    "#         df_M = np.hstack((df,music_array))\n",
    "#         # print(df.shape)\n",
    "#         # print(music_array.shape)\n",
    "#         savepath = savedir+filename+'_'+ combo_strings[i]\n",
    "#         # print(df_M.shape)\n",
    "#         np.savez_compressed(savepath,df_M)\n",
    "#         # print(i)\n",
    "#         i+=1\n",
    "\n",
    "\n",
    "# #Save to external HDD as compressed npz files \n",
    "# savedir = 'F:/EEG-data/numpy/featureExtraction/'\n",
    "\n",
    "# #Generators with only PSD features, polynomial\n",
    "# add_music_col_gen(C_poly_PSD_combos_df_gen,'C',combo_strings,'C_poly_PSD_combosM',savedir)\n",
    "# add_music_col_gen(H_poly_PSD_combos_df_gen,'H',combo_strings,'H_poly_PSD_combosM',savedir)\n",
    "# add_music_col_gen(W_poly_PSD_combos_df_gen,'W',combo_strings,'W_poly_PSD_combosM',savedir)\n",
    "\n",
    "# #Generators with only AUC features, polynomial\n",
    "# add_music_col(C_poly_AUC_combos_df_gen,'C',combo_strings,'C_poly_AUC_combosM', savedir)\n",
    "# add_music_col(H_poly_AUC_combos_df_gen,'H',combo_strings,'H_poly_AUC_combosM', savedir)\n",
    "# add_music_col(W_poly_AUC_combos_df_gen,'W',combo_strings,'W_poly_AUC_combosM', savedir)\n",
    "\n",
    "# #Generators with both features, polynomial\n",
    "# add_music_col_gen(C_poly_2F_combos_df_gen,'C',combo_strings,'C_poly_2F_combosM',savedir)\n",
    "# add_music_col_gen(H_poly_2F_combos_df_gen,'H',combo_strings,'H_poly_2F_combosM',savedir)\n",
    "# add_music_col_gen(W_poly_2F_combos_df_gen,'W',combo_strings,'W_poly_2F_combosM',savedir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510\n",
      "639\n",
      "494\n"
     ]
    }
   ],
   "source": [
    "print(len(C_2F_combosM_df_list[0].index))\n",
    "print(len(H_2F_combosM_df_list[0].index))\n",
    "print(len(W_2F_combosM_df_list[0].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine different music types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training, cross-validation, test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondafec408329ab14439ad38a72910c89f48"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
