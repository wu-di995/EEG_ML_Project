{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bit4f00f251aa71407b905d36ad95b25cdd",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Music SVM Classifier\n",
    "\n",
    "Goal: Classify types of music by EEG features \n",
    "\n",
    "3 types of music: White Noise, Classical, Hip-Hop\n",
    "Lengths of music (raw): \n",
    "    White Noise: 5934 recorded samples\n",
    "    Classical:   6128 recorded samples\n",
    "    Hip-Hop:     7674 recorded samples\n",
    "Data collection: 128 samples/s, 32 Channels \n",
    "\n",
    "No.of 0.1s samples in filtered data:\n",
    "    White Noise: 494\n",
    "    Classical:   510\n",
    "    Hip-Hop:     639 \n",
    "    \n",
    "Steps:\n",
    "1. Feature Scaling\n",
    "- Save feature scaled datasets \n",
    "\n",
    "2. Split dataset into Train and Test sets\n",
    "- 80%-20% Train test stratified shuffle split (keeps same proportion of each class in each set)\n",
    "\n",
    "3. SVM classification \n",
    "- Perform grid search for SVM parameters on each dataset\n",
    "- Determine the best feature parameters and features \n",
    "\n",
    "4. SVM evaluation\n",
    "- Using the best feature parameters, fit on the test sets  \n",
    "\n",
    "Work Done:1,2,3,4\n",
    "\n",
    "Problems: \n",
    "1. Grid search takes too long to run when C = 100\n",
    "\n",
    "Future work: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pickle as pkl\n",
    "import itertools \n",
    "import glob\n",
    "from sklearn import svm \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "# %matplotlib inline \n",
    "%matplotlib qt\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "\n",
    "#Load datasets \n",
    "loaddir = 'F:/EEG-data/pkl/featureExtraction/'\n",
    "loadAUC_dir = loaddir+'AUC_only/'\n",
    "loadPSD_dir = loaddir+'PSD_only/'\n",
    "loadAUC_PSD_dir = loaddir+'AUC_PSD/'\n",
    "\n",
    "savedir = 'F:/EEG-data/pkl/featureScaled/'\n",
    "saveAUC_dir = savedir+'AUC_only/'\n",
    "savePSD_dir = savedir+'PSD_only/'\n",
    "saveAUC_PSD_dir = savedir+'AUC_PSD/'\n",
    "\n",
    "#Function for feature scaling\n",
    "def featureScaling_df(loaddir,savedir):\n",
    "    sc = StandardScaler()\n",
    "    files = glob.glob(loaddir+'*pkl')\n",
    "    for file in files:\n",
    "        filename = file.split(\"\\\\\")[-1]\n",
    "        df = pd.read_pickle(file)\n",
    "        cols = df.columns\n",
    "        data = df.iloc[:,0:-1]\n",
    "        music = df.iloc[:,-1].values\n",
    "        music = np.reshape(music,(len(music),1))\n",
    "        scaled_data = sc.fit_transform(data)\n",
    "        new_df = pd.DataFrame(np.hstack((scaled_data,music)),columns=cols)\n",
    "        savefile = savedir+filename\n",
    "        new_df.to_pickle(savefile)\n",
    "        # new_df.to_csv(savefile+'.csv')\n",
    "\n",
    "# featureScaling_df(loadPSD_dir,savePSD_dir)\n",
    "# featureScaling_df(loadAUC_dir,saveAUC_dir)\n",
    "# featureScaling_df(loadAUC_PSD_dir,saveAUC_PSD_dir)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1643, 160)\n(1643,)\n"
    }
   ],
   "source": [
    "# Load feature scaled datasets\n",
    "loaddir = 'F:/EEG-data/pkl/featureScaled/'\n",
    "loadAUC_dir = loaddir+'AUC_only/'\n",
    "loadPSD_dir = loaddir+'PSD_only/'\n",
    "loadAUC_PSD_dir = loaddir+'AUC_PSD/'\n",
    "\n",
    "files = glob.glob(loadAUC_PSD_dir+'*.pkl')\n",
    "test_data = pd.read_pickle(files[0])\n",
    "\n",
    "X = test_data.iloc[:,:-1].values\n",
    "y = test_data.iloc[:,-1].values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-fd1478839dbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mSVM_CV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloadAUC_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveAUC_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[0mSVM_CV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloadPSD_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msavePSD_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mSVM_CV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloadAUC_PSD_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveAUC_PSD_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-fd1478839dbe>\u001b[0m in \u001b[0;36mSVM_CV\u001b[1;34m(loaddir, savedir)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m#Instantiate grid search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1_macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;31m#Get results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mresults_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Run cross validation, fit on test set and save all the results\n",
    "\n",
    "def SVM_CV(loaddir,savedir):\n",
    "    files = glob.glob(loaddir+'*.pkl')\n",
    "    sss = StratifiedShuffleSplit(n_splits=5,test_size=0.2,random_state=0)\n",
    "    #Parameter values to be searched\n",
    "    # param_grid = {'C': loguniform(1e0, 1e3),\n",
    "    #             'gamma': [loguniform(1e-4, 1e-3),'auto','scale'],\n",
    "    #             'kernel': ['linear','rbf']}\n",
    "    # param_grid = {'C': [1,3,10,30,100],\n",
    "    #             'gamma': [1e-4, 1e-3,'auto','scale'],\n",
    "    #             'kernel': ['linear','rbf']}\n",
    "    C_range = [1,3,10,30]\n",
    "    param_grid= [\n",
    "                {'C': C_range, 'kernel': ['linear']},\n",
    "                {'C': C_range, 'gamma': [0.001, 0.0001, 'auto', 'scale'], 'kernel': ['rbf']},\n",
    "                ]\n",
    "    scoring = {'accuracy','f1_macro'}\n",
    "    #SVM classifer\n",
    "    clf = svm.SVC()\n",
    "    for file in files:\n",
    "        df = pd.read_pickle(file)\n",
    "        cv_filename = file.split(\"\\\\\")[-1] +'CV_results.pkl'\n",
    "        # test_filename = file.split(\"\\\\\")[-1] +'test_results.pkl'\n",
    "        X = df.iloc[:,:-1].values\n",
    "        y = df.iloc[:,-1].values\n",
    "        #Split into training and test sets\n",
    "        for train_index, test_index in sss.split(X,y):\n",
    "            X_train, X_test = X[train_index],X[test_index]\n",
    "            y_train, y_test = y[train_index],y[test_index]\n",
    "        #Instantiate grid search\n",
    "        grid = GridSearchCV(clf,param_grid=param_grid,scoring=scoring,cv=5,refit='f1_macro')\n",
    "        grid.fit(X_train,y_train)\n",
    "        #Get results\n",
    "        results_df = pd.DataFrame(grid.cv_results_)\n",
    "        #Export results\n",
    "        results_df.to_pickle(savedir+cv_filename)\n",
    "        #Get best model parameters and test on test set \n",
    "\n",
    "\n",
    "loaddir = 'F:/EEG-data/pkl/featureScaled/'\n",
    "loadAUC_dir = loaddir+'AUC_only/'\n",
    "loadPSD_dir = loaddir+'PSD_only/'\n",
    "loadAUC_PSD_dir = loaddir+'AUC_PSD/'\n",
    "\n",
    "savedir = 'F:/EEG-data/pkl/0.1s_results/'\n",
    "saveAUC_dir = savedir+'AUC_only/'\n",
    "savePSD_dir = savedir+'PSD_only/'\n",
    "saveAUC_PSD_dir = savedir+'AUC_PSD/'\n",
    "\n",
    "\n",
    "SVM_CV(loadAUC_dir,saveAUC_dir)\n",
    "SVM_CV(loadPSD_dir,savePSD_dir)\n",
    "SVM_CV(loadAUC_PSD_dir,saveAUC_PSD_dir)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation on test sets \n",
    "\n",
    "#Data directories \n",
    "datadir = 'F:/EEG-data/pkl/featureScaled/'\n",
    "dataAUC_dir = datadir+'AUC_only/'\n",
    "dataPSD_dir = datadir+'PSD_only/'\n",
    "dataAUC_PSD_dir = datadir+'AUC_PSD/'\n",
    "#Results directories \n",
    "resdir ='F:\\EEG-data\\pkl\\\\0.1s_results/' \n",
    "resAUC_dir = resdir+'AUC_only/'\n",
    "resPSD_dir = resdir+'PSD_only/'\n",
    "resAUC_PSD_dir = resdir+'AUC_PSD/'\n",
    "#Save directories \n",
    "testdir = 'F:\\EEG-data\\pkl\\\\0.1s_results\\\\testResults/'\n",
    "testAUC_dir = testdir+'AUC_only/'\n",
    "testPSD_dir = testdir+'PSD_only/'\n",
    "testAUC_PSD_dir = testdir+'AUC_PSD/'\n",
    "\n",
    "\n",
    "def SVM_test(datadir,resdir,testdir):\n",
    "    sss = StratifiedShuffleSplit(n_splits=5,test_size=0.2,random_state=0)\n",
    "    datafiles = glob.glob(datadir+'*.pkl')\n",
    "    resfiles = glob.glob(resdir+'*.pkl')\n",
    "    bestF1 = {'F1 Score':0,'dataset':'','params':''}\n",
    "    test_results = {'F1 Score':[],'dataset':[],'params':[]}\n",
    "    if len(datafiles) == len(resfiles):\n",
    "        for i in range(len(datafiles)):\n",
    "            #Read files\n",
    "            data = pd.read_pickle(datafiles[i])\n",
    "            dfname = datafiles[i].split(\"\\\\\")[-1].rstrip('.pkl')\n",
    "            CVres = pd.read_pickle(resfiles[i])\n",
    "            #Split into train and test sets \n",
    "            X = data.iloc[:,:-1].values\n",
    "            y = data.iloc[:,-1].values\n",
    "            for train_index, test_index in sss.split(X,y):\n",
    "                X_train, X_test = X[train_index],X[test_index]\n",
    "                y_train, y_test = y[train_index],y[test_index]\n",
    "            #Fit SVM on best parameters \n",
    "            best_params = CVres.loc[CVres['rank_test_f1_macro'].idxmin()]['params']\n",
    "            clf = svm.SVC(**best_params)\n",
    "            clf.fit(X_train,y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            #Generate and save classification report, macro-avg f1 score, confusion matrix\n",
    "            ##Classification report \n",
    "            target_names = ['C','H','W']\n",
    "            report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "            report_df = pd.DataFrame(report).transpose()\n",
    "            report_df.to_pickle(testdir+dfname+'.pkl')\n",
    "            ##Macro-avg f1 score \n",
    "            f1Score = report['macro avg']['f1-score']\n",
    "            test_results['F1 Score'].append(f1Score)\n",
    "            test_results['dataset'].append(dfname)\n",
    "            test_results['params'].append(best_params)\n",
    "            test_results_df = pd.DataFrame(test_results)\n",
    "            if bestF1['F1 Score']<f1Score:\n",
    "                bestF1['F1 Score'] = f1Score\n",
    "                bestF1['dataset'] = dfname\n",
    "                bestF1['params'] = str(best_params)\n",
    "            ##Confusion matrix\n",
    "            fig,ax = plt.subplots()\n",
    "            ax.set_title(dfname+' CM')\n",
    "            plot_confusion_matrix(clf,X_test,y_test,labels=target_names,ax=ax)\n",
    "            plt.savefig(testdir+dfname+'.png')\n",
    "            plt.close()\n",
    "    else:\n",
    "        print(\"Number of files do not match.\")\n",
    "    bestF1_df = pd.DataFrame(bestF1,index=[0],columns=['F1 Score','dataset','params'])\n",
    "    bestF1_df.to_csv(testdir+bestF1['dataset']+'.csv')\n",
    "    test_results_df.to_csv(testdir+'test_results.csv')\n",
    "    test_results_df.to_csv(testdir+'test_results.pkl')\n",
    "    print(bestF1_df)\n",
    "    return test_results_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "F1 Score      dataset                                      params\n0  0.795252  AUC_df_0124  {'C': 3, 'gamma': 'auto', 'kernel': 'rbf'}\n"
    }
   ],
   "source": [
    "AUC_results_df = SVM_test(dataAUC_dir,resAUC_dir,testAUC_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "F1 Score       dataset                                     params\n0  0.816176  PSD_df_01234  {'C': 3, 'gamma': 0.001, 'kernel': 'rbf'}\n"
    }
   ],
   "source": [
    "PSD_results_df = SVM_test(dataPSD_dir,resPSD_dir,testPSD_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "F1 Score         dataset                                       params\n0  0.811716  AUC_PSD_df_123  {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n"
    }
   ],
   "source": [
    "AUC_PSD_results_df = SVM_test(dataAUC_PSD_dir,resAUC_PSD_dir,testAUC_PSD_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot results\n",
    "\n",
    "def plot_barF1_barFreqBands(results_df,testdir):\n",
    "    sorted_df = results_df.sort_values(by=['F1 Score'],ascending=False)\n",
    "    strip = ''\n",
    "    splitList = sorted_df['dataset'][1].split(\"_\")\n",
    "    for i in range(len(splitList)-1):\n",
    "        strip+=(splitList[i]+\"_\")\n",
    "    sorted_labels = [x.lstrip(strip) for x in sorted_df['dataset']]\n",
    "    color = [0]*31\n",
    "    color_range = ['tab:blue','tab:orange','tab:green','tab:purple','tab:red']\n",
    "    for i in range(len(sorted_labels)):\n",
    "        color[i] = color_range[len(sorted_labels[i])-1]\n",
    "    fig1,ax1 = plt.subplots(figsize=(50,10))\n",
    "    ax1.bar(sorted_labels,sorted_df['F1 Score'], color=color)\n",
    "    figtitle = ''\n",
    "    for i in range(len(splitList)):\n",
    "        if splitList[i]=='df':\n",
    "            break \n",
    "        else:\n",
    "            figtitle+=splitList[i]+\" \"\n",
    "\n",
    "    # build the legend\n",
    "    blue_patch = mpatches.Patch(color='tab:blue', label='1 band')\n",
    "    orange_patch = mpatches.Patch(color='tab:orange', label='2 bands')\n",
    "    green_patch = mpatches.Patch(color='tab:green', label='3 bands')\n",
    "    purple_patch = mpatches.Patch(color='tab:purple', label='4 bands')\n",
    "    red_patch = mpatches.Patch(color='red', label='5 bands')\n",
    "\n",
    "    # set up for handles declaration\n",
    "    patches = [blue_patch, orange_patch, green_patch, purple_patch,red_patch]\n",
    "    ax1.legend(handles=patches)\n",
    "    ax1.set_title(figtitle+'results,showing different frequency band combinations',fontsize=20)\n",
    "    ax1.set_xlabel('Datasets: 0-Delta,1-Theta,2-Alpha,3-Beta,4-Gamma',fontsize=20)\n",
    "    ax1.set_ylabel('F1 Score',fontsize=20)\n",
    "    plt.savefig(testdir+figtitle+' F1score_barchart.png')\n",
    "\n",
    "    #Figure for frequency band counts \n",
    "    fig2,ax2 = plt.subplots(figsize=(50,10))\n",
    "    counts10 = [0]*5\n",
    "    for label in sorted_labels[0:10]:\n",
    "        for i in range(len(label)):\n",
    "            num = int(label[i])\n",
    "            counts10[num]+=1\n",
    "    ax2.bar(['Delta','Theta','Alpha','Beta','Gamma'],counts10)\n",
    "    ax2.set_title(figtitle+' results,frequency band counts in 10 highest F1 scores',fontsize=20)\n",
    "    ax2.set_xlabel('Frequency Bands',fontsize=20)\n",
    "    ax2.set_ylabel('Counts',fontsize=20)\n",
    "    \n",
    "    plt.savefig(testdir+figtitle+'FrequencyBandCounts_barchart.png')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barF1_barFreqBands(AUC_results_df,testAUC_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barF1_barFreqBands(PSD_results_df,testPSD_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barF1_barFreqBands(AUC_PSD_results_df,testAUC_PSD_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########Code snippets for future use ##############\n",
    "\n",
    "#Cross Validation Score \n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# cv = StratifiedShuffleSplit(n_splits=5,test_size=0.2,random_state=0)\n",
    "# cross_val_score(clf, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "#Predict on test results\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# y_pred = clf.predict(X_test)\n",
    "# accuracy_score(y_test, y_pred)\n",
    "\n",
    "#Randomized Grid Search \n",
    "# from sklearn.utils.fixes import loguniform \n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "#Parameter values to be searched\n",
    "# param_grid = {'C': loguniform(1e0, 1e3),\n",
    "#  'gamma': [loguniform(1e-4, 1e-3),'auto','scale'],\n",
    "#  'kernel': ['rbf'],\n",
    "#  }\n",
    "\n",
    "# scoring = {'accuracy','f1_macro'}\n",
    "#SVM classifer\n",
    "# clf = svm.SVC()\n",
    "\n",
    "#Instantiate grid search\n",
    "# grid = RandomizedSearchCV(clf,param_distributions=param_grid,scoring=scoring,cv=5,refit='f1_macro')\n",
    "# grid.fit(X_train,y_train)\n",
    "\n",
    "#View results\n",
    "# pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n",
    "# df = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "# examine the best model\n",
    "# print(grid.best_score_)\n",
    "# print(grid.best_params_)"
   ]
  }
 ]
}