{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing multiple neural net architectures on time series data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pickle as pkl\n",
    "import itertools \n",
    "import glob\n",
    "from sklearn import svm \n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "%matplotlib inline \n",
    "# %matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing raw data files \n",
    "\n",
    "#.csv paths\n",
    "csvdir = \"C:/Users/Wu Di/Documents/EEG-analysis/200108-Readings-csv/\"\n",
    "classical_csvpath = csvdir + \"classical-music.csv\"\n",
    "hiphop_csvpath = csvdir + \"hip-hop.csv\"\n",
    "whitenoise_csvpath = csvdir + \"white-noise.csv\"\n",
    "\n",
    "#Read .csv files\n",
    "cols_to_use = list(range(3, 35))\n",
    "\n",
    "#Raw dataframes - each channel is a column\n",
    "classical_df = pd.read_csv(classical_csvpath, header=None, usecols=cols_to_use)\n",
    "hiphop_df = pd.read_csv(hiphop_csvpath, header=None, usecols=cols_to_use)\n",
    "whitenoise_df = pd.read_csv(whitenoise_csvpath, header=None, usecols=cols_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bandpass (BP) filter helper functions\n",
    "\n",
    "#Creates butterworth BP filter\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5*fs  # Nyquist frequency, which is half of fs\n",
    "    low = lowcut/nyq  # Digital butterworth filter cutoffs must be normalized to Nyquist frequency\n",
    "    high = highcut/nyq\n",
    "    b, a = signal.butter(order, [low, high], btype=\"bandpass\")\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass(cutFreq,fs,order=5):\n",
    "    nyq = 0.5*fs\n",
    "    cutFreq = cutFreq/nyq\n",
    "    b,a = signal.butter(order,cutFreq,btype=\"lowpass\")\n",
    "    return b,a \n",
    "\n",
    "def butter_highpass(cutFreq,fs,order=5):\n",
    "    nyq = 0.5*fs\n",
    "    cutFreq = cutFreq/nyq\n",
    "    b,a = signal.butter(order,cutFreq,btype=\"highpass\")\n",
    "    return b,a \n",
    "\n",
    "#Applies butterworth BP filter\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "#     filtered_data = signal.lfilter(b, a, data)\n",
    "    filtered_data = signal.filtfilt(b,a,data)\n",
    "    return filtered_data\n",
    "\n",
    "#Applies butterworth lowpass filter\n",
    "def butter_lowpass_filter(data, cutFreq, fs, order=5):\n",
    "    b, a = butter_lowpass(cutFreq,fs,order=5)\n",
    "    filtered_data = signal.filtfilt(b,a,data)\n",
    "    return filtered_data\n",
    "\n",
    "#Applies butterworth lowpass filter\n",
    "def butter_highpass_filter(data, cutFreq, fs, order=5):\n",
    "    b, a = butter_highpass(cutFreq,fs,order=5)\n",
    "    filtered_data = signal.filtfilt(b,a,data)\n",
    "    return filtered_data\n",
    "\n",
    "#Applies butterworth BP filter to Pandas dataframe \n",
    "def bp_filter_df(df, lowcut, highcut, fs, order):\n",
    "    rows, cols = df.shape  # Get no. of rows and cols in df\n",
    "    new_index = range(1, rows+1)\n",
    "    new_cols = range(1, cols+1)\n",
    "    # Create new df with same no. of rows and cols\n",
    "    new_df = pd.DataFrame(index=new_index, columns=new_cols)\n",
    "    # new_df = new_df.fillna(0) #Fill in 0 for all values\n",
    "    for i in range(cols):  # Apply bp filter each column (channel) and saves in new_df\n",
    "        filt_col = butter_bandpass_filter(\n",
    "            df.iloc[:, i].values, lowcut, highcut, fs, order)\n",
    "        new_df[i+1] = filt_col\n",
    "    return new_df\n",
    "\n",
    "#Applies butterworth lowpass filter to Pandas dataframe \n",
    "def lp_filter_df(df, cutFreq, fs, order):\n",
    "    rows, cols = df.shape  # Get no. of rows and cols in df\n",
    "    new_index = range(1, rows+1)\n",
    "    new_cols = range(1, cols+1)\n",
    "    # Create new df with same no. of rows and cols\n",
    "    new_df = pd.DataFrame(index=new_index, columns=new_cols)\n",
    "    # new_df = new_df.fillna(0) #Fill in 0 for all values\n",
    "    for i in range(cols):  # Apply bp filter each column (channel) and saves in new_df\n",
    "        filt_col = butter_lowpass_filter(\n",
    "            df.iloc[:, i].values, cutFreq, fs, order)\n",
    "        new_df[i+1] = filt_col\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_classical_df = lp_filter_df(classical_df,40.5,128,6)\n",
    "filt_hiphop_df = lp_filter_df(hiphop_df,40.5,128,6)\n",
    "filt_whitenoise_df = lp_filter_df(whitenoise_df,40.5,128,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits a single dataframe into list of equally sized arrays\n",
    "#Each element in list is nx32 array, where n= sample length \n",
    "def split_df(df,fs,sample_t,check=False):\n",
    "    rows,_ = df.shape #get no. of rows\n",
    "    sample_len = int(sample_t*fs) #find no. of recorded samples required for each sample time length\n",
    "    Ns = int(rows/sample_len) #find total no. of samples\n",
    "    df_cut = df.iloc[:Ns*sample_len] #truncate dataframe to exact multiple of sample length\n",
    "    # print(Ns*sample_len)\n",
    "    # print(Ns)\n",
    "    df_split_list = np.vsplit(df_cut,Ns) #split dataframe row-wise, returns a list\n",
    "    \n",
    "    if check:\n",
    "        print(\"Total no. of recorded samples: \"+str(rows))\n",
    "        print(\"Sample length: \"+str(sample_len))\n",
    "        print(\"Total no. of samples: \"+str(Ns))\n",
    "        print(\"Length of df_split_list: \"+str(len(df_split_list)))\n",
    "        \n",
    "        if all(isinstance(x.shape,tuple) for x in df_split_list):\n",
    "            print(\"Shape of each element in df_split_list: \"+str(df_split_list[0].shape))\n",
    "        else:\n",
    "            print(\"Shapes are wrong.\")\n",
    "            for x in df_split_list:\n",
    "                print(x.shape)\n",
    "    return df_split_list,Ns\n",
    "\n",
    "#Apply split_df() function to list of dataframes, reshape dataframe such that each element is an array \n",
    "#for the appropriate sample time length \n",
    "def split_bands_list(bands_list,fs,sample_t,check=False,checkSD=False):\n",
    "    df_list_rFE = [0]*len(bands_list) #dataframes list ready for feature extraction \n",
    "    for df_no in range(len(bands_list)):\n",
    "        df_split_list,Ns = split_df(bands_list[df_no],fs,sample_t,check=checkSD)\n",
    "        list_of_series = [0]*Ns\n",
    "        for i in range(len(df_split_list)):\n",
    "            #New dataframe will have shape Nsx32, each element is a 1xsample_len array \n",
    "            new_row = [0]*32 \n",
    "            #Each df_split_list[i] is a dataframe\n",
    "            for j in range(len(df_split_list[i].columns)):\n",
    "                new_row[j] = df_split_list[i].iloc[:,j].values \n",
    "            list_of_series[i] = new_row\n",
    "        df_list_rFE[df_no] = pd.DataFrame(list_of_series)\n",
    "    if check:\n",
    "        print(\"Length of bands_list: \"+str(len(bands_list)))\n",
    "        print(\"Length of df_list_rFE: \"+str(len(df_list_rFE)))\n",
    "        if (all(isinstance(x.shape,tuple) for x in df_list_rFE)) and (Ns==len(df_list_rFE[0].index)):\n",
    "            print(\"Shape of each dataframe in df_list_rFE: \"+str(df_list_rFE[0].shape))\n",
    "    return df_list_rFE\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #0.05s \n",
    "# split005_c_df=split_bands_list([classical_df],128,0.05)[0]\n",
    "# split005_h_df=split_bands_list([hiphop_df],128,0.05)[0]\n",
    "# split005_w_df=split_bands_list([whitenoise_df],128,0.05)[0]\n",
    "\n",
    "# #0.1s \n",
    "# split01_c_df=split_bands_list([classical_df],128,0.1)[0]\n",
    "# split01_h_df=split_bands_list([hiphop_df],128,0.1)[0]\n",
    "# split01_w_df=split_bands_list([whitenoise_df],128,0.1)[0]\n",
    "\n",
    "\n",
    "# #0.05s filt\n",
    "# fsplit005_c_df=split_bands_list([filt_classical_df],128,0.05)[0]\n",
    "# fsplit005_h_df=split_bands_list([filt_hiphop_df],128,0.05)[0]\n",
    "# fsplit005_w_df=split_bands_list([filt_whitenoise_df],128,0.05)[0]\n",
    "\n",
    "# #0.1s filt\n",
    "# fsplit01_c_df=split_bands_list([filt_classical_df],128,0.1)[0]\n",
    "# fsplit01_h_df=split_bands_list([filt_hiphop_df],128,0.1)[0]\n",
    "# fsplit01_w_df=split_bands_list([filt_whitenoise_df],128,0.1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1021, 32)\n(1279, 32)\n(989, 32)\n(510, 32)\n(639, 32)\n(494, 32)\n"
    }
   ],
   "source": [
    "# print(split005_c_df.shape)\n",
    "# print(split005_h_df.shape)\n",
    "# print(split005_w_df.shape)\n",
    "\n",
    "# print(split01_c_df.shape)\n",
    "# print(split01_h_df.shape)\n",
    "# print(split01_w_df.shape)\n",
    "\n",
    "# print(fsplit005_c_df.shape)\n",
    "# print(fsplit005_h_df.shape)\n",
    "# print(fsplit005_w_df.shape)\n",
    "\n",
    "# print(fsplit01_c_df.shape)\n",
    "# print(fsplit01_h_df.shape)\n",
    "# print(fsplit01_w_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save datasets\n",
    "# split005_c_df.to_pickle(\"F:\\EEG-data\\music\\\\raw\\\\0.05s/raw_classical.pkl\")\n",
    "# split005_h_df.to_pickle(\"F:\\EEG-data\\music\\\\raw\\\\0.05s/raw_hiphop.pkl\")\n",
    "# split005_w_df.to_pickle(\"F:\\EEG-data\\music\\\\raw\\\\0.05s/raw_whitenoise.pkl\")\n",
    "\n",
    "# split01_c_df.to_pickle(\"F:\\EEG-data\\music\\\\raw\\\\0.1s/raw_classical.pkl\")\n",
    "# split01_h_df.to_pickle(\"F:\\EEG-data\\music\\\\raw\\\\0.1s/raw_hiphop.pkl\")\n",
    "# split01_w_df.to_pickle(\"F:\\EEG-data\\music\\\\raw\\\\0.1s/raw_whitenoise.pkl\")\n",
    "\n",
    "# Filt \n",
    "# fsplit005_c_df.to_pickle(\"F:\\EEG-data\\music\\\\filtered\\\\0.05s/lp40.5_classical.pkl\")\n",
    "# fsplit005_h_df.to_pickle(\"F:\\EEG-data\\music\\\\filtered\\\\0.05s/lp40.5_hiphop.pkl\")\n",
    "# fsplit005_w_df.to_pickle(\"F:\\EEG-data\\music\\\\filtered\\\\0.05s/lp40.5_whitenoise.pkl\")\n",
    "\n",
    "# fsplit01_c_df.to_pickle(\"F:\\EEG-data\\music\\\\filtered\\\\0.1s/lp40.5_classical.pkl\")\n",
    "# fsplit01_h_df.to_pickle(\"F:\\EEG-data\\music\\\\filtered\\\\0.1s/lp40.5_hiphop.pkl\")\n",
    "# fsplit01_w_df.to_pickle(\"F:\\EEG-data\\music\\\\filtered\\\\0.1s/lp40.5_whitenoise.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #0.05s \n",
    "# c_df005 = pd.read_pickle(\"F:\\EEG-data\\music\\\\raw\\\\0.05s/raw_classical.pkl\")\n",
    "# h_df005 = pd.read_pickle(\"F:\\EEG-data\\music\\\\raw\\\\0.05s/raw_hiphop.pkl\")\n",
    "# w_df005 = pd.read_pickle(\"F:\\EEG-data\\music\\\\raw\\\\0.05s/raw_whitenoise.pkl\")\n",
    "\n",
    "# #0.1s\n",
    "# c_df01 = pd.read_pickle(\"F:\\EEG-data\\music\\\\raw\\\\0.1s/raw_classical.pkl\")\n",
    "# h_df01 = pd.read_pickle(\"F:\\EEG-data\\music\\\\raw\\\\0.1s/raw_hiphop.pkl\")\n",
    "# w_df01 = pd.read_pickle(\"F:\\EEG-data\\music\\\\raw\\\\0.1s/raw_whitenoise.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.05s \n",
    "fc_df005 = pd.read_pickle(\"F:\\EEG-data\\music\\\\filtered\\\\0.05s/lp40.5_classical.pkl\")\n",
    "fh_df005 = pd.read_pickle(\"F:\\EEG-data\\music\\\\filtered\\\\0.05s/lp40.5_hiphop.pkl\")\n",
    "fw_df005 = pd.read_pickle(\"F:\\EEG-data\\music\\\\filtered\\\\0.05s/lp40.5_whitenoise.pkl\")\n",
    "\n",
    "#0.1s\n",
    "fc_df01 = pd.read_pickle(\"F:\\EEG-data\\music\\\\filtered\\\\0.1s/lp40.5_classical.pkl\")\n",
    "fh_df01 = pd.read_pickle(\"F:\\EEG-data\\music\\\\filtered\\\\0.1s/lp40.5_hiphop.pkl\")\n",
    "fw_df01 = pd.read_pickle(\"F:\\EEG-data\\music\\\\filtered\\\\0.1s/lp40.5_whitenoise.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1021, 32)\n(1279, 32)\n(989, 32)\n(510, 32)\n(639, 32)\n(494, 32)\n"
    }
   ],
   "source": [
    "# print(c_df005.shape)\n",
    "# print(h_df005.shape)\n",
    "# print(w_df005.shape)\n",
    "\n",
    "# print(c_df01.shape)\n",
    "# print(h_df01.shape)\n",
    "# print(w_df01.shape)\n",
    "\n",
    "print(fc_df005.shape)\n",
    "print(fh_df005.shape)\n",
    "print(fw_df005.shape)\n",
    "\n",
    "print(fc_df01.shape)\n",
    "print(fh_df01.shape)\n",
    "print(fw_df01.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape each dataframe into 320,12,32\n",
    "def reshape_df(df):\n",
    "    sampLen = len(df.iloc[0,0])\n",
    "    N = df.shape[0]\n",
    "    new_df = np.zeros((N,sampLen,32))\n",
    "    for i in range(32):\n",
    "        channel = df.iloc[:,i].values \n",
    "        channel_df = np.zeros((N,sampLen))\n",
    "        for j in range(len(channel)):\n",
    "            channel_df[j,:] = channel[j]\n",
    "        new_df[:,:,i] = keras.utils.normalize(channel_df)\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #0.05s\n",
    "# c_df005r = reshape_df(c_df005)\n",
    "# h_df005r = reshape_df(h_df005)\n",
    "# w_df005r = reshape_df(w_df005)\n",
    "\n",
    "# #0.1s\n",
    "# c_df01r = reshape_df(c_df01)\n",
    "# h_df01r = reshape_df(h_df01)\n",
    "# w_df01r = reshape_df(w_df01)\n",
    "\n",
    "#Filtered\n",
    "#0.05s\n",
    "fc_df005r = reshape_df(fc_df005)\n",
    "fh_df005r = reshape_df(fh_df005)\n",
    "fw_df005r = reshape_df(fw_df005)\n",
    "\n",
    "#0.1s\n",
    "fc_df01r = reshape_df(fc_df01)\n",
    "fh_df01r = reshape_df(fh_df01)\n",
    "fw_df01r = reshape_df(fw_df01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1021, 6, 32)\n(1279, 6, 32)\n(989, 6, 32)\n(510, 12, 32)\n(639, 12, 32)\n(494, 12, 32)\n"
    }
   ],
   "source": [
    "# #0.05s\n",
    "# print(c_df005r.shape)\n",
    "# print(h_df005r.shape)\n",
    "# print(w_df005r.shape)\n",
    "\n",
    "# #0.1s\n",
    "# print(c_df01r.shape)\n",
    "# print(h_df01r.shape)\n",
    "# print(w_df01r.shape)\n",
    "\n",
    "##Filtered\n",
    "#0.05s\n",
    "print(fc_df005r.shape)\n",
    "print(fh_df005r.shape)\n",
    "print(fw_df005r.shape)\n",
    "\n",
    "#0.1s\n",
    "print(fc_df01r.shape)\n",
    "print(fh_df01r.shape)\n",
    "print(fw_df01r.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(3289, 6, 32)\n(3289,)\n(1643, 12, 32)\n(1643,)\n"
    }
   ],
   "source": [
    "#0.05\n",
    "X005 = np.vstack((c_df005r,h_df005r,w_df005r))\n",
    "y005 = np.hstack((np.zeros(c_df005r.shape[0]),np.ones(h_df005r.shape[0]),2*np.ones(w_df005r.shape[0])))\n",
    "print(X005.shape)\n",
    "print(y005.shape)\n",
    "#0.1\n",
    "X01 = np.vstack((c_df01r,h_df01r,w_df01r))\n",
    "y01 = np.hstack((np.zeros(c_df01r.shape[0]),np.ones(h_df01r.shape[0]),2*np.ones(w_df01r.shape[0])))\n",
    "print(X01.shape)\n",
    "print(y01.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(3289, 6, 32)\n(3289,)\n(1643, 12, 32)\n(1643,)\n"
    }
   ],
   "source": [
    "## FILTERED\n",
    "\n",
    "#0.05\n",
    "fX005 = np.vstack((fc_df005r,fh_df005r,fw_df005r))\n",
    "fy005 = np.hstack((np.zeros(fc_df005r.shape[0]),np.ones(fh_df005r.shape[0]),2*np.ones(fw_df005r.shape[0])))\n",
    "print(fX005.shape)\n",
    "print(fy005.shape)\n",
    "#0.1\n",
    "fX01 = np.vstack((fc_df01r,fh_df01r,fw_df01r))\n",
    "fy01 = np.hstack((np.zeros(fc_df01r.shape[0]),np.ones(fh_df01r.shape[0]),2*np.ones(fw_df01r.shape[0])))\n",
    "print(fX01.shape)\n",
    "print(fy01.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test sets\n",
    "def split_train_test(X,y):\n",
    "    sss = StratifiedShuffleSplit(n_splits=5,test_size=0.2,random_state=0)\n",
    "    for train_index, test_index in sss.split(X,y):\n",
    "                x_train, x_test = X[train_index],X[test_index]\n",
    "                y_train, y_test = y[train_index],y[test_index]\n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.05s\n",
    "x_train005,x_test005,y_train005,y_test005 = split_train_test(X005,y005)\n",
    "#0.1s\n",
    "x_train01,x_test01,y_train01,y_test01 = split_train_test(X01,y01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTERED\n",
    "#0.05s\n",
    "fx_train005,fx_test005,fy_train005,fy_test005 = split_train_test(fX005,fy005)\n",
    "#0.1s\n",
    "fx_train01,fx_test01,fy_train01,fy_test01 = split_train_test(fX01,fy01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DNN model\n",
    "def DNN_model(sampLen):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(sampLen*32, input_shape = (sampLen,32), activation=\"relu\"),\n",
    "        tf.keras.layers.Flatten(), \n",
    "        tf.keras.layers.Dense(10, activation=\"relu\"), \n",
    "        tf.keras.layers.Dense(3,activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer='adam',\n",
    "                metrics=[\"accuracy\"])\n",
    "    # model.summary()\n",
    "    return model\n",
    "\n",
    "#Conv model\n",
    "def CONV_model(sampLen):\n",
    "    model2 = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv1D(filters=128, kernel_size=5,strides=1, padding=\"causal\",\n",
    "                                activation=\"relu\",input_shape=(sampLen,32)), #input shape = (n_timesteps,n_features)\n",
    "        tf.keras.layers.Conv1D(filters=64, kernel_size=5,strides=1, padding=\"causal\",activation=\"relu\"),\n",
    "        tf.keras.layers.Conv1D(filters=32, kernel_size=5,strides=1, padding=\"causal\",activation=\"relu\"),\n",
    "        # tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.MaxPool1D(pool_size=2),\n",
    "        tf.keras.layers.Conv1D(filters=16, kernel_size=5,strides=1, padding=\"causal\",activation=\"relu\"),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation=\"relu\"), \n",
    "        # tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(3,activation=\"softmax\")\n",
    "    ])\n",
    "    # optimizer = tf.keras.optimizers.Adam(lr=9e-4)\n",
    "    model2.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])\n",
    "    return model2\n",
    "\n",
    "#Conv + LSTM\n",
    "def CONV_LSTM_model(sampLen):\n",
    "    model3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=128, kernel_size=5,strides=1, padding=\"causal\",\n",
    "                              activation=\"relu\",input_shape=(sampLen,32)), #input shape = (n_timesteps,n_features)\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=5,strides=1, padding=\"causal\",activation=\"relu\"),\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=5,strides=1, padding=\"causal\",activation=\"relu\"),\n",
    "    # tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=16, kernel_size=5,strides=1, padding=\"causal\",activation=\"relu\"),\n",
    "    # tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
    "    tf.keras.layers.Dense(10, activation=\"relu\"), \n",
    "    # tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(3,activation=\"softmax\")\n",
    "])\n",
    "    model3.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=[\"accuracy\"])\n",
    "    return model3\n",
    "\n",
    "#Simple RNN \n",
    "def RNN_model(sampLen):\n",
    "    model4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(40, input_shape = (sampLen,32),return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(40),\n",
    "    # tf.keras.layers.Dense(10,activation=\"relu\",input_shape=(12,32)),\n",
    "    tf.keras.layers.Dense(3,activation=\"softmax\"),\n",
    "    ])\n",
    "    model4.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer='adam',\n",
    "                metrics=[\"accuracy\"])\n",
    "    return model4\n",
    "\n",
    "#LSTM only\n",
    "\n",
    "def LSTM_model(sampLen):\n",
    "    model5 = tf.keras.models.Sequential([\n",
    "    # tf.keras.layers.Flatten(input_shape=(sampLen,32)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True,input_shape=(sampLen,32))),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(3,activation=\"softmax\"),\n",
    "    ])\n",
    "    model5.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer='adam',\n",
    "                metrics=[\"accuracy\"])\n",
    "    return model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.05s \n",
    "dataset005 = tf.data.Dataset.from_tensor_slices((x_train005,y_train005))\n",
    "devset005  = tf.data.Dataset.from_tensor_slices((x_test005,y_test005))\n",
    "dataset005b = dataset005.batch(40)\n",
    "devset005b = devset005.batch(40)\n",
    "\n",
    "# 0.1s \n",
    "dataset01 = tf.data.Dataset.from_tensor_slices((x_train01,y_train01))\n",
    "devset01  = tf.data.Dataset.from_tensor_slices((x_test01,y_test01))\n",
    "dataset01b = dataset01.batch(40)\n",
    "devset01b = devset01.batch(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTERED\n",
    "# 0.05s \n",
    "fdataset005 = tf.data.Dataset.from_tensor_slices((fx_train005,fy_train005))\n",
    "fdevset005  = tf.data.Dataset.from_tensor_slices((fx_test005,fy_test005))\n",
    "fdataset005b = fdataset005.batch(40)\n",
    "fdevset005b = fdevset005.batch(40)\n",
    "\n",
    "# 0.1s \n",
    "fdataset01 = tf.data.Dataset.from_tensor_slices((fx_train01,fy_train01))\n",
    "fdevset01  = tf.data.Dataset.from_tensor_slices((fx_test01,fy_test01))\n",
    "fdataset01b = fdataset01.batch(40)\n",
    "fdevset01b = fdevset01.batch(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,dataset,devset,batchsize,epochs):\n",
    "    tf.random.set_seed(10)\n",
    "    datasetb = dataset.batch(batchsize)\n",
    "    devsetb = devset.batch(batchsize)\n",
    "    history = model.fit(datasetb,epochs=epochs,verbose=0,validation_data=devsetb)\n",
    "    return history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Layer bidirectional_21 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\n0.9924012422561646\n0.9954407215118408\n0.9878419637680054\n0.9924012422561646\n0.975683867931366\n"
    }
   ],
   "source": [
    "# 0.05s \n",
    "# Testing different models, epochs=10, batchsize = 1 \n",
    "sampLen = 6 \n",
    "DNN_model005 = DNN_model(sampLen)\n",
    "CONV_model005 = CONV_model(sampLen)\n",
    "CONV_LSTM_model005 = CONV_LSTM_model(sampLen)\n",
    "LSTM_model005 = LSTM_model(sampLen)\n",
    "RNN_model005 = RNN_model(sampLen)\n",
    "#Histories \n",
    "DNN_hist005 = test(DNN_model005,dataset005,devset005,1,10)\n",
    "CONV_hist005 = test(CONV_model005,dataset005,devset005,1,10)\n",
    "CONV_LSTM_hist005 = test(CONV_LSTM_model005,dataset005,devset005,1,10)\n",
    "LSTM_hist005 = test(LSTM_model005,dataset005,devset005,1,10)\n",
    "RNN_hist005 = test(RNN_model005,dataset005,devset005,1,10)\n",
    "#Max validation accuracy \n",
    "valacc_DNN005 = max(DNN_hist005.history['val_accuracy'])\n",
    "valacc_CONV005 = max(CONV_hist005.history['val_accuracy'])\n",
    "valacc_CONVLSTM005 = max(CONV_LSTM_hist005.history['val_accuracy'])\n",
    "valacc_LSTM005 = max(LSTM_hist005.history['val_accuracy'])\n",
    "valacc_RNN005 = max(RNN_hist005.history['val_accuracy'])\n",
    "\n",
    "print(valacc_DNN005)\n",
    "print(valacc_CONV005)\n",
    "print(valacc_CONVLSTM005)\n",
    "print(valacc_LSTM005)\n",
    "print(valacc_RNN005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Layer bidirectional_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nFiltered validation accuracies\n0.9924012422561646\n0.9924012422561646\n0.9878419637680054\n0.9939209818840027\n0.9772036671638489\n"
    }
   ],
   "source": [
    "#### FILTERED ####\n",
    "# 0.05s \n",
    "# Testing different models, epochs=10, batchsize = 1 \n",
    "sampLen = 6 \n",
    "DNN_model005 = DNN_model(sampLen)\n",
    "CONV_model005 = CONV_model(sampLen)\n",
    "CONV_LSTM_model005 = CONV_LSTM_model(sampLen)\n",
    "LSTM_model005 = LSTM_model(sampLen)\n",
    "RNN_model005 = RNN_model(sampLen)\n",
    "#Histories \n",
    "DNN_hist005f = test(DNN_model005,fdataset005,fdevset005,1,10)\n",
    "CONV_hist005f = test(CONV_model005,fdataset005,fdevset005,1,10)\n",
    "CONV_LSTM_hist005f = test(CONV_LSTM_model005,fdataset005,fdevset005,1,10)\n",
    "LSTM_hist005f = test(LSTM_model005,fdataset005,fdevset005,1,10)\n",
    "RNN_hist005f = test(RNN_model005,fdataset005,fdevset005,1,10)\n",
    "#Max validation accuracy \n",
    "valacc_DNN005f = max(DNN_hist005f.history['val_accuracy'])\n",
    "valacc_CONV005f = max(CONV_hist005f.history['val_accuracy'])\n",
    "valacc_CONVLSTM005f = max(CONV_LSTM_hist005f.history['val_accuracy'])\n",
    "valacc_LSTM005f = max(LSTM_hist005f.history['val_accuracy'])\n",
    "valacc_RNN005f = max(RNN_hist005f.history['val_accuracy'])\n",
    "\n",
    "print(\"Filtered validation accuracies\")\n",
    "print(valacc_DNN005f)\n",
    "print(valacc_CONV005f)\n",
    "print(valacc_CONVLSTM005f)\n",
    "print(valacc_LSTM005f)\n",
    "print(valacc_RNN005f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Layer bidirectional_24 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\n1.0\n0.996960461139679\n0.9817629456520081\n0.996960461139679\n0.9665653705596924\n"
    }
   ],
   "source": [
    "# 0.1s \n",
    "# Testing different models, epochs=10, batchsize = 1 \n",
    "sampLen = 12\n",
    "DNN_model01 = DNN_model(sampLen)\n",
    "CONV_model01 = CONV_model(sampLen)\n",
    "CONV_LSTM_model01 = CONV_LSTM_model(sampLen)\n",
    "LSTM_model01 = LSTM_model(sampLen)\n",
    "RNN_model01 = RNN_model(sampLen)\n",
    "#Histories \n",
    "DNN_hist01 = test(DNN_model01,dataset01,devset01,1,10)\n",
    "CONV_hist01 = test(CONV_model01,dataset01,devset01,1,10)\n",
    "CONV_LSTM_hist01 = test(CONV_LSTM_model01,dataset01,devset01,1,10)\n",
    "LSTM_hist01 = test(LSTM_model01,dataset01,devset01,1,10)\n",
    "RNN_hist01 = test(RNN_model01,dataset01,devset01,1,10)\n",
    "#Max validation accuracy \n",
    "valacc_DNN01 = max(DNN_hist01.history['val_accuracy'])\n",
    "valacc_CONV01 = max(CONV_hist01.history['val_accuracy'])\n",
    "valacc_CONVLSTM01 = max(CONV_LSTM_hist01.history['val_accuracy'])\n",
    "valacc_LSTM01 = max(LSTM_hist01.history['val_accuracy'])\n",
    "valacc_RNN01 = max(RNN_hist01.history['val_accuracy'])\n",
    "\n",
    "print(valacc_DNN01)\n",
    "print(valacc_CONV01)\n",
    "print(valacc_CONVLSTM01)\n",
    "print(valacc_LSTM01)\n",
    "print(valacc_RNN01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Layer bidirectional_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nFiltered validation accuracies\n1.0\n0.996960461139679\n0.9908814430236816\n1.0\n0.975683867931366\n"
    }
   ],
   "source": [
    "##### FILTERED ########\n",
    "#0.1s\n",
    "# Testing different models, epochs=10, batchsize = 1 \n",
    "sampLen = 12\n",
    "DNN_model01 = DNN_model(sampLen)\n",
    "CONV_model01 = CONV_model(sampLen)\n",
    "CONV_LSTM_model01 = CONV_LSTM_model(sampLen)\n",
    "LSTM_model01 = LSTM_model(sampLen)\n",
    "RNN_model01 = RNN_model(sampLen)\n",
    "#Histories \n",
    "DNN_hist01f = test(DNN_model01,fdataset01,fdevset01,1,10)\n",
    "CONV_hist01f = test(CONV_model01,fdataset01,fdevset01,1,10)\n",
    "CONV_LSTM_hist01f = test(CONV_LSTM_model01,fdataset01,fdevset01,1,10)\n",
    "LSTM_hist01f = test(LSTM_model01,fdataset01,fdevset01,1,10)\n",
    "RNN_hist01f = test(RNN_model01,fdataset01,fdevset01,1,10)\n",
    "#Max validation accuracy \n",
    "valacc_DNN01f = max(DNN_hist01f.history['val_accuracy'])\n",
    "valacc_CONV01f = max(CONV_hist01f.history['val_accuracy'])\n",
    "valacc_CONVLSTM01f = max(CONV_LSTM_hist01f.history['val_accuracy'])\n",
    "valacc_LSTM01f = max(LSTM_hist01f.history['val_accuracy'])\n",
    "valacc_RNN01f = max(RNN_hist01f.history['val_accuracy'])\n",
    "\n",
    "print(\"Filtered validation accuracies\")\n",
    "print(valacc_DNN01f)\n",
    "print(valacc_CONV01f)\n",
    "print(valacc_CONVLSTM01f)\n",
    "print(valacc_LSTM01f)\n",
    "print(valacc_RNN01f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing different batch sizes \n",
    "def test_batchsizes(model,dataset,devset,batchsizes,epochs):\n",
    "    histories = []\n",
    "    for batchsize in batchsizes:\n",
    "        histories.append(test(model,dataset,devset,batchsize,epochs))\n",
    "    return histories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-233-6b3ee07ec1e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mhists_maxvalacc_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mhistories\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatchsizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatchsizes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistories\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"batch size: {}, val acc: {}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhists_maxvalacc_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDNN01_histories\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatchsizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhists_maxvalacc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDNN01_histories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"batch size: {}, val acc: {}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhists_maxvalacc_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCONV01_histories\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatchsizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhists_maxvalacc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCONV01_histories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"batch size: {}, val acc: {}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhists_maxvalacc_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCONV_LSTM_01_histories\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatchsizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhists_maxvalacc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCONV_LSTM_01_histories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-233-6b3ee07ec1e2>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(histories, batchsizes)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mhists_maxvalacc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mhistories\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistories\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mhists_maxvalacc_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mhistories\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatchsizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatchsizes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistories\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"batch size: {}, val acc: {}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhists_maxvalacc_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDNN01_histories\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatchsizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhists_maxvalacc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDNN01_histories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "# 0.1s \n",
    "batchsizes = list(range(1,40,10))\n",
    "\n",
    "DNN01_histories = test_batchsizes(DNN_model01,dataset01,devset01,batchsizes,10)\n",
    "CONV01_histories = test_batchsizes(CONV_model01,dataset01,devset01,batchsizes,10)\n",
    "CONV_LSTM_01_histories = test_batchsizes(CONV_LSTM_model01,dataset01,devset01,batchsizes,10)\n",
    "LSTM_01_histories = test_batchsizes(LSTM_model01,dataset01,devset01,batchsizes,10)\n",
    "RNN01_histories = test_batchsizes(RNN_model01,dataset01,devset01,batchsizes,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "batch size: 1, val acc: 0.996960461139679\nbatch size: 1, val acc: 1.0\nbatch size: 1, val acc: 0.996960461139679\nbatch size: 31, val acc: 0.9939209818840027\nbatch size: 1, val acc: 0.9848024249076843\n"
    }
   ],
   "source": [
    "hists_maxvalacc = lambda histories: max([history.history['val_accuracy'][-1] for history in histories])\n",
    "hists_maxvalacc_batch = lambda histories,batchsizes: batchsizes[np.argmax(np.array([history.history['val_accuracy'][-1] for history in histories]))]\n",
    "\n",
    "print(\"batch size: {}, val acc: {}\".format(hists_maxvalacc_batch(DNN01_histories,batchsizes),hists_maxvalacc(DNN01_histories)))\n",
    "print(\"batch size: {}, val acc: {}\".format(hists_maxvalacc_batch(CONV01_histories,batchsizes),hists_maxvalacc(CONV01_histories)))\n",
    "print(\"batch size: {}, val acc: {}\".format(hists_maxvalacc_batch(CONV_LSTM_01_histories,batchsizes),hists_maxvalacc(CONV_LSTM_01_histories)))\n",
    "print(\"batch size: {}, val acc: {}\".format(hists_maxvalacc_batch(LSTM_01_histories,batchsizes),hists_maxvalacc(LSTM_01_histories)))\n",
    "print(\"batch size: {}, val acc: {}\".format(hists_maxvalacc_batch(RNN01_histories,batchsizes),hists_maxvalacc(RNN01_histories)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTERED 0.1s \n",
    "batchsizes = list(range(1,40,10))\n",
    "\n",
    "DNN01_historiesf = test_batchsizes(DNN_model01,dataset01f,devset01f,batchsizes,10)\n",
    "CONV01_historiesf = test_batchsizes(CONV_model01,dataset01f,devset01f,batchsizes,10)\n",
    "CONV_LSTM_01_historiesf = test_batchsizes(CONV_LSTM_model01f,dataset01f,devset01,batchsizes,10)\n",
    "LSTM_01_historiesf = test_batchsizes(LSTM_model01,dataset01f,devset01f,batchsizes,10)\n",
    "RNN01_historiesf = test_batchsizes(RNN_model01,dataset01f,devset01f,batchsizes,10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists_maxvalacc = lambda histories: max([history.history['val_accuracy'][-1] for history in histories])\n",
    "hists_maxvalacc_batch = lambda histories,batchsizes: batchsizes[np.argmax(np.array([history.history['val_accuracy'][-1] for history in histories]))]\n",
    "\n",
    "print(\"batch size: {}, val acc: {}\".format(hists_maxvalacc_batch(DNN01_historiesf,batchsizes),hists_maxvalacc(DNN01_histories)))\n",
    "print(\"batch size: {}, val acc: {}\".format(hists_maxvalacc_batch(CONV01_historiesf,batchsizes),hists_maxvalacc(CONV01_histories)))\n",
    "print(\"batch size: {}, val acc: {}\".format(hists_maxvalacc_batch(CONV_LSTM_01_historiesf,batchsizes),hists_maxvalacc(CONV_LSTM_01_histories)))\n",
    "print(\"batch size: {}, val acc: {}\".format(hists_maxvalacc_batch(LSTM_01_historiesf,batchsizes),hists_maxvalacc(LSTM_01_histories)))\n",
    "print(\"batch size: {}, val acc: {}\".format(hists_maxvalacc_batch(RNN01_historiesf,batchsizes),hists_maxvalacc(RNN01_histories)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n33/33 [==============================] - 0s 14ms/step - loss: 0.6764 - accuracy: 0.7633 - val_loss: 0.3098 - val_accuracy: 0.9362\nEpoch 2/10\n33/33 [==============================] - 0s 8ms/step - loss: 0.1943 - accuracy: 0.9551 - val_loss: 0.1162 - val_accuracy: 0.9666\nEpoch 3/10\n33/33 [==============================] - 0s 7ms/step - loss: 0.0797 - accuracy: 0.9840 - val_loss: 0.0659 - val_accuracy: 0.9939\nEpoch 4/10\n33/33 [==============================] - 0s 7ms/step - loss: 0.0424 - accuracy: 0.9962 - val_loss: 0.0453 - val_accuracy: 0.9939\nEpoch 5/10\n33/33 [==============================] - 0s 8ms/step - loss: 0.0261 - accuracy: 0.9992 - val_loss: 0.0351 - val_accuracy: 0.9939\nEpoch 6/10\n33/33 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9939\nEpoch 7/10\n33/33 [==============================] - 0s 9ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9939\nEpoch 8/10\n33/33 [==============================] - 0s 12ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9939\nEpoch 9/10\n31/33 [===========================>..] - ETA: 0s - loss: 0.0074 - accuracy: 1.0033/33 [==============================] - 0s 9ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9970\nEpoch 10/10\n33/33 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9970\n"
    }
   ],
   "source": [
    "sampLen=12\n",
    "model = DNN_model(sampLen)\n",
    "history = model.fit(dataset01b,epochs=10,validation_data=devset01b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_67\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d_4 (Conv1D)            (None, 6, 128)            20608     \n_________________________________________________________________\nconv1d_5 (Conv1D)            (None, 6, 64)             41024     \n_________________________________________________________________\nconv1d_6 (Conv1D)            (None, 6, 32)             10272     \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 3, 32)             0         \n_________________________________________________________________\nconv1d_7 (Conv1D)            (None, 3, 16)             2576      \n_________________________________________________________________\nflatten_30 (Flatten)         (None, 48)                0         \n_________________________________________________________________\ndense_190 (Dense)            (None, 10)                490       \n_________________________________________________________________\ndense_191 (Dense)            (None, 3)                 33        \n=================================================================\nTotal params: 75,003\nTrainable params: 75,003\nNon-trainable params: 0\n_________________________________________________________________\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-195-da4ee6d4905f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mDNN_005_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCONV_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# DNN_005_model.fit(dataset005b,epochs=10,validation_data=devset005b)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mDNN_005_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDNN_005_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset005\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevset005\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-175-4555322856dd>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model, dataset, devset, batchsize, epochs)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdatasetb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdevsetb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasetb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevsetb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 0.05s \n",
    "sampLen = 6\n",
    "DNN_005_model = DNN_model(sampLen)\n",
    "# DNN_005_model.fit(dataset005b,epochs=10,validation_data=devset005b)\n",
    "DNN_005_history = test(DNN_005_model,dataset005,devset005,10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x1ae1ed4fda0>]"
     },
     "metadata": {},
     "execution_count": 189
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 378.465625 248.518125\" width=\"378.465625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;white-space:pre;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 378.465625 248.518125 \r\nL 378.465625 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 371.265625 224.64 \r\nL 371.265625 7.2 \r\nL 36.465625 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mec2c8e3d23\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#mec2c8e3d23\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(48.502557 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"113.17141\" xlink:href=\"#mec2c8e3d23\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(106.80891 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"174.659013\" xlink:href=\"#mec2c8e3d23\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 40 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(168.296513 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"236.146617\" xlink:href=\"#mec2c8e3d23\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 60 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(229.784117 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"297.63422\" xlink:href=\"#mec2c8e3d23\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 80 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(291.27172 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"359.121823\" xlink:href=\"#mec2c8e3d23\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 100 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(349.578073 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m07e51ead57\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m07e51ead57\" y=\"210.729316\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.86 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 214.528535)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m07e51ead57\" y=\"183.065648\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.88 -->\r\n      <g transform=\"translate(7.2 186.864866)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m07e51ead57\" y=\"155.401979\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.90 -->\r\n      <defs>\r\n       <path d=\"M 10.984375 1.515625 \r\nL 10.984375 10.5 \r\nQ 14.703125 8.734375 18.5 7.8125 \r\nQ 22.3125 6.890625 25.984375 6.890625 \r\nQ 35.75 6.890625 40.890625 13.453125 \r\nQ 46.046875 20.015625 46.78125 33.40625 \r\nQ 43.953125 29.203125 39.59375 26.953125 \r\nQ 35.25 24.703125 29.984375 24.703125 \r\nQ 19.046875 24.703125 12.671875 31.3125 \r\nQ 6.296875 37.9375 6.296875 49.421875 \r\nQ 6.296875 60.640625 12.9375 67.421875 \r\nQ 19.578125 74.21875 30.609375 74.21875 \r\nQ 43.265625 74.21875 49.921875 64.515625 \r\nQ 56.59375 54.828125 56.59375 36.375 \r\nQ 56.59375 19.140625 48.40625 8.859375 \r\nQ 40.234375 -1.421875 26.421875 -1.421875 \r\nQ 22.703125 -1.421875 18.890625 -0.6875 \r\nQ 15.09375 0.046875 10.984375 1.515625 \r\nz\r\nM 30.609375 32.421875 \r\nQ 37.25 32.421875 41.125 36.953125 \r\nQ 45.015625 41.5 45.015625 49.421875 \r\nQ 45.015625 57.28125 41.125 61.84375 \r\nQ 37.25 66.40625 30.609375 66.40625 \r\nQ 23.96875 66.40625 20.09375 61.84375 \r\nQ 16.21875 57.28125 16.21875 49.421875 \r\nQ 16.21875 41.5 20.09375 36.953125 \r\nQ 23.96875 32.421875 30.609375 32.421875 \r\nz\r\n\" id=\"DejaVuSans-57\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 159.201198)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m07e51ead57\" y=\"127.738311\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.92 -->\r\n      <g transform=\"translate(7.2 131.537529)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m07e51ead57\" y=\"100.074642\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.94 -->\r\n      <g transform=\"translate(7.2 103.873861)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m07e51ead57\" y=\"72.410973\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.96 -->\r\n      <g transform=\"translate(7.2 76.210192)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m07e51ead57\" y=\"44.747305\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.98 -->\r\n      <g transform=\"translate(7.2 48.546524)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m07e51ead57\" y=\"17.083636\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 1.00 -->\r\n      <g transform=\"translate(7.2 20.882855)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_15\">\r\n    <path clip-path=\"url(#pe5460eb827)\" d=\"M 51.683807 214.756364 \r\nL 54.758187 52.832989 \r\nL 57.832567 32.329705 \r\nL 60.906947 21.815189 \r\nL 63.981327 18.660793 \r\nL 67.055708 18.660793 \r\nL 70.130088 19.186539 \r\nL 73.204468 19.186539 \r\nL 76.278848 18.135047 \r\nL 79.353228 17.609383 \r\nL 82.427608 17.609383 \r\nL 85.501989 17.083636 \r\nL 88.576369 17.083636 \r\nL 91.650749 17.609383 \r\nL 94.725129 25.495249 \r\nL 97.799509 18.660793 \r\nL 100.873889 17.083636 \r\nL 103.94827 17.083636 \r\nL 107.02265 17.083636 \r\nL 110.09703 17.083636 \r\nL 113.17141 17.083636 \r\nL 116.24579 17.083636 \r\nL 119.32017 17.083636 \r\nL 122.394551 17.083636 \r\nL 125.468931 17.083636 \r\nL 128.543311 17.083636 \r\nL 131.617691 17.083636 \r\nL 134.692071 17.083636 \r\nL 137.766451 17.083636 \r\nL 140.840832 17.083636 \r\nL 143.915212 17.083636 \r\nL 146.989592 17.083636 \r\nL 150.063972 17.083636 \r\nL 153.138352 17.083636 \r\nL 156.212732 17.083636 \r\nL 159.287113 17.083636 \r\nL 162.361493 17.083636 \r\nL 165.435873 17.083636 \r\nL 168.510253 17.083636 \r\nL 171.584633 17.083636 \r\nL 174.659013 17.083636 \r\nL 177.733394 17.083636 \r\nL 180.807774 17.083636 \r\nL 183.882154 17.083636 \r\nL 186.956534 17.083636 \r\nL 190.030914 17.083636 \r\nL 193.105294 17.083636 \r\nL 196.179675 17.083636 \r\nL 199.254055 17.083636 \r\nL 202.328435 17.083636 \r\nL 205.402815 17.083636 \r\nL 208.477195 17.083636 \r\nL 211.551575 17.083636 \r\nL 214.625956 17.083636 \r\nL 217.700336 17.083636 \r\nL 220.774716 17.083636 \r\nL 223.849096 17.083636 \r\nL 226.923476 17.083636 \r\nL 229.997856 17.083636 \r\nL 233.072237 17.083636 \r\nL 236.146617 17.083636 \r\nL 239.220997 17.083636 \r\nL 242.295377 17.083636 \r\nL 245.369757 17.083636 \r\nL 248.444137 17.083636 \r\nL 251.518518 17.083636 \r\nL 254.592898 17.083636 \r\nL 257.667278 17.083636 \r\nL 260.741658 17.083636 \r\nL 263.816038 17.083636 \r\nL 266.890418 17.083636 \r\nL 269.964799 17.083636 \r\nL 273.039179 17.083636 \r\nL 276.113559 17.083636 \r\nL 279.187939 17.083636 \r\nL 282.262319 17.083636 \r\nL 285.336699 17.083636 \r\nL 288.41108 17.083636 \r\nL 291.48546 17.083636 \r\nL 294.55984 17.083636 \r\nL 297.63422 17.083636 \r\nL 300.7086 17.083636 \r\nL 303.78298 17.083636 \r\nL 306.857361 17.083636 \r\nL 309.931741 17.083636 \r\nL 313.006121 17.083636 \r\nL 316.080501 17.083636 \r\nL 319.154881 17.083636 \r\nL 322.229261 17.083636 \r\nL 325.303642 17.083636 \r\nL 328.378022 17.083636 \r\nL 331.452402 17.083636 \r\nL 334.526782 17.083636 \r\nL 337.601162 17.083636 \r\nL 340.675542 17.083636 \r\nL 343.749923 17.083636 \r\nL 346.824303 17.083636 \r\nL 349.898683 17.083636 \r\nL 352.973063 17.083636 \r\nL 356.047443 17.083636 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_16\">\r\n    <path clip-path=\"url(#pe5460eb827)\" d=\"M 51.683807 73.84042 \r\nL 54.758187 54.921465 \r\nL 57.832567 44.410989 \r\nL 60.906947 38.10467 \r\nL 63.981327 38.10467 \r\nL 67.055708 36.002592 \r\nL 70.130088 36.002592 \r\nL 73.204468 38.10467 \r\nL 76.278848 29.696273 \r\nL 79.353228 31.798352 \r\nL 82.427608 33.900431 \r\nL 85.501989 29.696273 \r\nL 88.576369 27.594112 \r\nL 91.650749 33.900431 \r\nL 94.725129 38.10467 \r\nL 97.799509 25.492033 \r\nL 100.873889 29.696273 \r\nL 103.94827 27.594112 \r\nL 107.02265 27.594112 \r\nL 110.09703 27.594112 \r\nL 113.17141 27.594112 \r\nL 116.24579 27.594112 \r\nL 119.32017 27.594112 \r\nL 122.394551 27.594112 \r\nL 125.468931 25.492033 \r\nL 128.543311 25.492033 \r\nL 131.617691 25.492033 \r\nL 134.692071 25.492033 \r\nL 137.766451 25.492033 \r\nL 140.840832 25.492033 \r\nL 143.915212 27.594112 \r\nL 146.989592 27.594112 \r\nL 150.063972 27.594112 \r\nL 153.138352 27.594112 \r\nL 156.212732 27.594112 \r\nL 159.287113 27.594112 \r\nL 162.361493 27.594112 \r\nL 165.435873 27.594112 \r\nL 168.510253 27.594112 \r\nL 171.584633 27.594112 \r\nL 174.659013 27.594112 \r\nL 177.733394 27.594112 \r\nL 180.807774 27.594112 \r\nL 183.882154 27.594112 \r\nL 186.956534 27.594112 \r\nL 190.030914 27.594112 \r\nL 193.105294 27.594112 \r\nL 196.179675 27.594112 \r\nL 199.254055 27.594112 \r\nL 202.328435 27.594112 \r\nL 205.402815 27.594112 \r\nL 208.477195 27.594112 \r\nL 211.551575 27.594112 \r\nL 214.625956 27.594112 \r\nL 217.700336 29.696273 \r\nL 220.774716 29.696273 \r\nL 223.849096 29.696273 \r\nL 226.923476 29.696273 \r\nL 229.997856 29.696273 \r\nL 233.072237 29.696273 \r\nL 236.146617 29.696273 \r\nL 239.220997 29.696273 \r\nL 242.295377 29.696273 \r\nL 245.369757 29.696273 \r\nL 248.444137 29.696273 \r\nL 251.518518 29.696273 \r\nL 254.592898 29.696273 \r\nL 257.667278 29.696273 \r\nL 260.741658 29.696273 \r\nL 263.816038 29.696273 \r\nL 266.890418 29.696273 \r\nL 269.964799 29.696273 \r\nL 273.039179 29.696273 \r\nL 276.113559 29.696273 \r\nL 279.187939 29.696273 \r\nL 282.262319 29.696273 \r\nL 285.336699 29.696273 \r\nL 288.41108 29.696273 \r\nL 291.48546 29.696273 \r\nL 294.55984 29.696273 \r\nL 297.63422 29.696273 \r\nL 300.7086 29.696273 \r\nL 303.78298 29.696273 \r\nL 306.857361 29.696273 \r\nL 309.931741 29.696273 \r\nL 313.006121 29.696273 \r\nL 316.080501 29.696273 \r\nL 319.154881 29.696273 \r\nL 322.229261 29.696273 \r\nL 325.303642 29.696273 \r\nL 328.378022 29.696273 \r\nL 331.452402 29.696273 \r\nL 334.526782 29.696273 \r\nL 337.601162 29.696273 \r\nL 340.675542 29.696273 \r\nL 343.749923 29.696273 \r\nL 346.824303 29.696273 \r\nL 349.898683 29.696273 \r\nL 352.973063 29.696273 \r\nL 356.047443 29.696273 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 36.465625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 371.265625 224.64 \r\nL 371.265625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 371.265625 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 36.465625 7.2 \r\nL 371.265625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pe5460eb827\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.plot(DNN_005_history.history[\"accuracy\"])\n",
    "plt.plot(DNN_005_history.history[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1s \n",
    "sampLen = 12\n",
    "DNN_01_model = DNN_model(sampLen)\n",
    "DNN_01_history = test(DNN_01_model,dataset01,devset01,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x1ae1f002d68>]"
     },
     "metadata": {},
     "execution_count": 194
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 384.828125 248.518125\" width=\"384.828125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;white-space:pre;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 384.828125 248.518125 \r\nL 384.828125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 42.828125 224.64 \r\nL 377.628125 224.64 \r\nL 377.628125 7.2 \r\nL 42.828125 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m0df73b7aa8\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.046307\" xlink:href=\"#m0df73b7aa8\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(54.865057 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"125.68267\" xlink:href=\"#m0df73b7aa8\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 2 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(122.50142 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"193.319034\" xlink:href=\"#m0df73b7aa8\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 4 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(190.137784 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"260.955398\" xlink:href=\"#m0df73b7aa8\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 6 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(257.774148 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"328.591761\" xlink:href=\"#m0df73b7aa8\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 8 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(325.410511 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_6\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"ma45fdea7eb\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.828125\" xlink:href=\"#ma45fdea7eb\" y=\"197.459969\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 0.850 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 201.259187)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.828125\" xlink:href=\"#ma45fdea7eb\" y=\"167.397247\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.875 -->\r\n      <defs>\r\n       <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 171.196465)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.828125\" xlink:href=\"#ma45fdea7eb\" y=\"137.334525\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.900 -->\r\n      <defs>\r\n       <path d=\"M 10.984375 1.515625 \r\nL 10.984375 10.5 \r\nQ 14.703125 8.734375 18.5 7.8125 \r\nQ 22.3125 6.890625 25.984375 6.890625 \r\nQ 35.75 6.890625 40.890625 13.453125 \r\nQ 46.046875 20.015625 46.78125 33.40625 \r\nQ 43.953125 29.203125 39.59375 26.953125 \r\nQ 35.25 24.703125 29.984375 24.703125 \r\nQ 19.046875 24.703125 12.671875 31.3125 \r\nQ 6.296875 37.9375 6.296875 49.421875 \r\nQ 6.296875 60.640625 12.9375 67.421875 \r\nQ 19.578125 74.21875 30.609375 74.21875 \r\nQ 43.265625 74.21875 49.921875 64.515625 \r\nQ 56.59375 54.828125 56.59375 36.375 \r\nQ 56.59375 19.140625 48.40625 8.859375 \r\nQ 40.234375 -1.421875 26.421875 -1.421875 \r\nQ 22.703125 -1.421875 18.890625 -0.6875 \r\nQ 15.09375 0.046875 10.984375 1.515625 \r\nz\r\nM 30.609375 32.421875 \r\nQ 37.25 32.421875 41.125 36.953125 \r\nQ 45.015625 41.5 45.015625 49.421875 \r\nQ 45.015625 57.28125 41.125 61.84375 \r\nQ 37.25 66.40625 30.609375 66.40625 \r\nQ 23.96875 66.40625 20.09375 61.84375 \r\nQ 16.21875 57.28125 16.21875 49.421875 \r\nQ 16.21875 41.5 20.09375 36.953125 \r\nQ 23.96875 32.421875 30.609375 32.421875 \r\nz\r\n\" id=\"DejaVuSans-57\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 141.133743)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.828125\" xlink:href=\"#ma45fdea7eb\" y=\"107.271803\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.925 -->\r\n      <g transform=\"translate(7.2 111.071021)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.828125\" xlink:href=\"#ma45fdea7eb\" y=\"77.20908\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.950 -->\r\n      <g transform=\"translate(7.2 81.008299)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.828125\" xlink:href=\"#ma45fdea7eb\" y=\"47.146358\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.975 -->\r\n      <g transform=\"translate(7.2 50.945577)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.828125\" xlink:href=\"#ma45fdea7eb\" y=\"17.083636\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 1.000 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 20.882855)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#pc2ed616a5c)\" d=\"M 58.046307 214.756364 \r\nL 91.864489 41.7927 \r\nL 125.68267 24.404819 \r\nL 159.500852 29.895778 \r\nL 193.319034 24.404819 \r\nL 227.137216 17.998784 \r\nL 260.955398 17.083636 \r\nL 294.77358 17.083636 \r\nL 328.591761 17.083636 \r\nL 362.409943 17.083636 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#pc2ed616a5c)\" d=\"M 58.046307 39.013856 \r\nL 91.864489 24.39371 \r\nL 125.68267 28.048782 \r\nL 159.500852 24.39371 \r\nL 193.319034 24.39371 \r\nL 227.137216 17.083636 \r\nL 260.955398 24.39371 \r\nL 294.77358 17.083636 \r\nL 328.591761 20.738709 \r\nL 362.409943 24.39371 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 42.828125 224.64 \r\nL 42.828125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 377.628125 224.64 \r\nL 377.628125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 42.828125 224.64 \r\nL 377.628125 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 42.828125 7.2 \r\nL 377.628125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pc2ed616a5c\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"42.828125\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.plot(DNN_01_history.history[\"accuracy\"])\n",
    "plt.plot(DNN_01_history.history[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_61\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_172 (Dense)            (None, 12, 384)           12672     \n_________________________________________________________________\ndense_173 (Dense)            (None, 12, 10)            3850      \n_________________________________________________________________\ndense_174 (Dense)            (None, 12, 3)             33        \n=================================================================\nTotal params: 16,555\nTrainable params: 16,555\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "sampLen = 12\n",
    "# model = tf.keras.models.Sequential([\n",
    "#         tf.keras.layers.Flatten(input_shape=(12,32)),\n",
    "#         # tf.keras.layers.Dense(sampLen*32, input_shape = (sampLen,32), activation=\"relu\"),\n",
    "#         # tf.keras.layers.Dense(sampLen*32,activation=\"relu\"), \n",
    "#         tf.keras.layers.Dense(128, activation=\"relu\"), \n",
    "#         tf.keras.layers.Dense(3,activation=\"softmax\")\n",
    "#         # tf.keras.layers.Dense(3)\n",
    "#     ])\n",
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(sampLen*32, input_shape = (sampLen,32), activation=\"relu\"), \n",
    "        tf.keras.layers.Dense(10, activation=\"relu\"), \n",
    "        tf.keras.layers.Dense(3,activation=\"softmax\")\n",
    "    ])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "            optimizer='adam',\n",
    "            metrics=[\"accuracy\"])\n",
    "            \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n"
    },
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": " assertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [32 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [32 12]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at <ipython-input-182-9a71af2f015a>:1) ]] [Op:__inference_train_function_29397]\n\nFunction call stack:\ntrain_function\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-182-9a71af2f015a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# model.fit(x_train01.reshape(1314,384),y_train01,epochs=10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# model.fit(X01,y01,epochs=10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  assertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [32 1] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [32 12]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert (defined at <ipython-input-182-9a71af2f015a>:1) ]] [Op:__inference_train_function_29397]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train01,y_train01,epochs=10,validation_data=)\n",
    "# model.fit(x_train01.reshape(1314,384),y_train01,epochs=10)\n",
    "# model.fit(X01,y01,epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1314,)"
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "source": [
    "ANN_model = keras.Sequential([\n",
    "# keras.layers.Flatten(input_shape=(8,32)),\n",
    "keras.layers.Dense(384,input_dim=no_features,activation='relu'),\n",
    "keras.layers.Dense(384/2, activation='relu'),\n",
    "keras.layers.Dense(384/4, activation='relu'),\n",
    "keras.layers.Dense(3,activation='softmax')])\n",
    "\n",
    "ANN_model.compile(optimizer=\"adam\",\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 0., 0.],\n       [2., 2., 2.],\n       [2., 1., 0.],\n       ...,\n       [0., 2., 2.],\n       [0., 1., 0.],\n       [1., 2., 0.]])"
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "y_train01.reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bit4f00f251aa71407b905d36ad95b25cdd",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}